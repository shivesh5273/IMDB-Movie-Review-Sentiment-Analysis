<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>IMDB_Review_Analysis</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KIDxnIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzQxNDE0MSI+CiAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiA8L2c+CiA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSguNDMgLjA0MDEpIiBmaWxsPSIjZmZmIj4KICA8cGF0aCBkPSJtNC4xNCA4Ljc2cTAuMDY4Mi0xLjg5IDIuNDItMS44OSAxLjE2IDAgMS42OCAwLjQyIDAuNTY3IDAuNDEgMC41NjcgMS4xNnYzLjQ3cTAgMC40NjIgMC41MTQgMC40NjIgMC4xMDMgMCAwLjItMC4wMjMxdjAuNzE0cS0wLjM5OSAwLjEwMy0wLjY1MSAwLjEwMy0wLjQ1MiAwLTAuNjkzLTAuMjItMC4yMzEtMC4yLTAuMjg0LTAuNjYyLTAuOTU2IDAuODcyLTIgMC44NzItMC45MDMgMC0xLjQ3LTAuNDcyLTAuNTI1LTAuNDcyLTAuNTI1LTEuMjYgMC0wLjI2MiAwLjA0NTItMC40NzIgMC4wNTY3LTAuMjIgMC4xMTYtMC4zNzggMC4wNjgyLTAuMTY4IDAuMjMxLTAuMzA0IDAuMTU4LTAuMTQ3IDAuMjYyLTAuMjQyIDAuMTE2LTAuMDkxNCAwLjM2OC0wLjE2OCAwLjI2Mi0wLjA5MTQgMC4zOTktMC4xMjYgMC4xMzYtMC4wNDUyIDAuNDcyLTAuMTAzIDAuMzM2LTAuMDU3OCAwLjUwNC0wLjA3OTggMC4xNTgtMC4wMjMxIDAuNTY3LTAuMDc5OCAwLjU1Ni0wLjA2ODIgMC43NzctMC4yMjEgMC4yMi0wLjE1MiAwLjIyLTAuNDQxdi0wLjI1MnEwLTAuNDMtMC4zNTctMC42NjItMC4zMzYtMC4yMzEtMC45NzYtMC4yMzEtMC42NjIgMC0wLjk5OCAwLjI2Mi0wLjMzNiAwLjI1Mi0wLjM5OSAwLjc5OHptMS44OSAzLjY4cTAuNzg4IDAgMS4yNi0wLjQxIDAuNTA0LTAuNDIgMC41MDQtMC45MDN2LTEuMDVxLTAuMjg0IDAuMTM2LTAuODYxIDAuMjMxLTAuNTY3IDAuMDkxNC0wLjk4NyAwLjE1OC0wLjQyIDAuMDY4Mi0wLjc2NiAwLjMyNi0wLjMzNiAwLjI1Mi0wLjMzNiAwLjcwNHQwLjMwNCAwLjcwNCAwLjg2MSAwLjI1MnoiIHN0cm9rZS13aWR0aD0iMS4wNSIvPgogIDxwYXRoIGQ9Im0xMCA0LjU2aDAuOTQ1djMuMTVxMC42NTEtMC45NzYgMS44OS0wLjk3NiAxLjE2IDAgMS44OSAwLjg0IDAuNjgyIDAuODQgMC42ODIgMi4zMSAwIDEuNDctMC43MDQgMi40Mi0wLjcwNCAwLjg4Mi0xLjg5IDAuODgyLTEuMjYgMC0xLjg5LTEuMDJ2MC43NjZoLTAuODV6bTIuNjIgMy4wNHEtMC43NDYgMC0xLjE2IDAuNjQtMC40NTIgMC42My0wLjQ1MiAxLjY4IDAgMS4wNSAwLjQ1MiAxLjY4dDEuMTYgMC42M3EwLjc3NyAwIDEuMjYtMC42MyAwLjQ5NC0wLjY0IDAuNDk0LTEuNjggMC0xLjA1LTAuNDcyLTEuNjgtMC40NjItMC42NC0xLjI2LTAuNjR6IiBzdHJva2Utd2lkdGg9IjEuMDUiLz4KICA8cGF0aCBkPSJtMi43MyAxNS44IDEzLjYgMC4wMDgxYzAuMDA2OSAwIDAtMi42IDAtMi42IDAtMC4wMDc4LTEuMTUgMC0xLjE1IDAtMC4wMDY5IDAtMC4wMDgzIDEuNS0wLjAwODMgMS41LTJlLTMgLTAuMDAxNC0xMS4zLTAuMDAxNC0xMS4zLTAuMDAxNGwtMC4wMDU5Mi0xLjVjMC0wLjAwNzgtMS4xNyAwLjAwMTMtMS4xNyAwLjAwMTN6IiBzdHJva2Utd2lkdGg9Ii45NzUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8a77807f92f26ee">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Applying-Machine-Learning-to-Sentiment-Analysis">Applying Machine Learning to Sentiment Analysis<a class="anchor-link" href="#Applying-Machine-Learning-to-Sentiment-Analysis"></a></h1><h2 id="Project:-IMDB-Movie-Review-Data">Project: IMDB Movie Review Data<a class="anchor-link" href="#Project:-IMDB-Movie-Review-Data"></a></h2><p>In the mordern internet and social media age, people's opinion, reviews and recommendations have become a valuable resource for businesses.
Thanks to modern technology, we are now able to collect and analyse such data more efficiently.
In this project, I will delve into the subfield of <strong>Natural Language Processing</strong> called <strong>Sentiment Analysis</strong>, and learn how to use machine learning algorithms to classify documents based on their popularity.
<strong>Sentiment Analysis</strong> is also called as <strong>Opinion Mining</strong>.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e080a0c270afb82b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Applying-Machine-Learning-to-Sentiment-Analysis">Applying Machine Learning to Sentiment Analysis<a class="anchor-link" href="#Applying-Machine-Learning-to-Sentiment-Analysis"></a></h1><h2 id="Obtaining-the-Movie-Review-Dataset">Obtaining the Movie Review Dataset<a class="anchor-link" href="#Obtaining-the-Movie-Review-Dataset"></a></h2><p>In this section, I prepare the <strong>IMDB movie review dataset</strong> that will be used
throughout the sentiment analysis project.</p>
<p>The goal is to make sure that:</p>
<ol>
<li>The notebook is running inside the correct project folder.</li>
<li>A <code>data/aclImdb</code> directory exists and contains the extracted IMDB dataset.</li>
<li>If the dataset is missing, the notebook prints clear instructions on what the
expected folder structure should look like.</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=58970f1ca74454b8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Step-A-%E2%80%93-Confirm-the-notebook-location">Step A  Confirm the notebook location<a class="anchor-link" href="#Step-A-%E2%80%93-Confirm-the-notebook-location"></a></h3><p>Before touching any data, I verify that the notebook is running inside the
expected project folder.</p>
<p>This small check helps avoid subtle bugs later, for example:</p>
<ul>
<li>running the notebook from a different directory,</li>
<li>saving files to the wrong place,</li>
<li>or accidentally creating duplicate <code>data/</code> folders.</li>
</ul>
<p>The next cell prints the <strong>current working directory</strong> so I can visually confirm
that it matches:</p>
<p><code>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis</code></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=2e22a1fd4f5f549d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># Double Check where the notebook is running</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">cProfile</span><span class="w"> </span><span class="kn">import</span> <span class="n">label</span>

<span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[1]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'/Users/shivesh/Desktop/PythonProject/Sentiment Analysis'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1018c02e1b9267bc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Step-B-%E2%80%93-Make-sure-the-IMDB-dataset-is-available-in-data/aclImdb">Step B  Make sure the IMDB dataset is available in <code>data/aclImdb</code><a class="anchor-link" href="#Step-B-%E2%80%93-Make-sure-the-IMDB-dataset-is-available-in-data/aclImdb"></a></h3><p>The IMDB movie review dataset is distributed as the archive
<code>aclImdb_v1.tar</code> (originally <code>aclImdb_v1.tar.gz</code>).</p>
<p>On this machine I downloaded and extracted it <strong>manually</strong>:</p>
<ol>
<li><p>Downloaded the archive from the Stanford URL in Safari.</p>
</li>
<li><p>Moved the file into the <code>Sentiment Analysis</code> project folder.</p>
</li>
<li><p>Extracted it (by double-clicking in Finder), which created a folder:</p>
<p><code>aclImdb/</code>  containing <code>train/</code> and <code>test/</code> subfolders.</p>
</li>
</ol>
<p>After that, I want the project to follow this structure:</p>
<div class="highlight"><pre><span></span>Sentiment Analysis/
  sample.ipynb
  data/
    aclImdb/
      train/
      test/
      ...
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=3a42959e0f604f61">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># Folder inside the project where we keep raw data</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">"data"</span>
<span class="n">IMDB_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">"aclImdb"</span><span class="p">)</span>

<span class="c1"># Make sure the data folder exists</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Check that the extracted dataset is in the right place</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">IMDB_DIR</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"IMDB dataset is ready at:"</span><span class="p">,</span> <span class="n">IMDB_DIR</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"IMDB dataset NOT found at:"</span><span class="p">,</span> <span class="n">IMDB_DIR</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Expected structure:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"  Sentiment Analysis/"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"    sample.ipynb"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"    data/aclImdb/{train,test,...}"</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Expected folder not found: </span><span class="si">{</span><span class="n">IMDB_DIR</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>IMDB dataset is ready at: data/aclImdb
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1b415af82e23adf2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Preprocessing-the-movie-dataset-into-a-more-convinient-format">Preprocessing the movie dataset into a more convinient format<a class="anchor-link" href="#Preprocessing-the-movie-dataset-into-a-more-convinient-format"></a></h2><p>To visualize the progress and estimated time until completion, we will use the <strong>Python Progress Indicator</strong>.
PyPind can be installed by executing the <em>"pip install pyprind"</em> command in the terminal.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=7f21362b5d2997">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pyprind</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># Base path of the unzipped movie dataset inside data/</span>
<span class="n">basepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">"data"</span><span class="p">,</span> <span class="s2">"aclImdb"</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'pos'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'neg'</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">pyprind</span><span class="o">.</span><span class="n">ProgBar</span><span class="p">(</span><span class="mi">50000</span><span class="p">)</span>

<span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c1"># temporary list to store [review_text, sentiment] pairs</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'test'</span><span class="p">,</span> <span class="s1">'train'</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'pos'</span><span class="p">,</span> <span class="s1">'neg'</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)):</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file</span><span class="p">),</span> <span class="s1">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
                <span class="n">txt</span> <span class="o">=</span> <span class="n">infile</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">txt</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">l</span><span class="p">]])</span>  <span class="c1"># store row instead of df.append</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

<span class="c1"># Build the DataFrame once from the collected rows</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'review'</span><span class="p">,</span> <span class="s1">'sentiment'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Warning: No valid output stream.
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d0b90c8f2e7b9b63">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Using Nested For Loops, we itreated over the <em>train</em> and the <em>test</em> subdirectories in the main aclImdb directory and read the individual text files from <em>pos</em> and <em>neg</em> subdirectories that we eventually appended to the <em>df</em> pandas <em>DataFrame</em>, together with the integer class label (1 = positive, 0 = negative )</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c337e1fc2fe784d0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Since the class labels in the assembled dataset are sorted, we will now shuffle <em>DataFrame</em> using the <strong>Permutation</strong> function from <em>np.random</em> submodule.
This will be useful to split the dataset into training and testing datasets in the later parts of the projects, when we will stream the data from our local drive directly.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=b12544c142dd2f92">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">'movie_data.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c759ca1d79e62367">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><em>df = df.read_csv('movie_data.csv', encoding='utf-8')</em></p>
<p>No need to read the CSV again in the same session.
Right now, at the end of the previous cell you already have:
<em>df.to_csv('movie_data.csv', index=False, encoding='utf-8')</em></p>
<p>df is still in memory, so you can just do:
<em>df.head()</em></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=1f99dba23d90eac9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>review</th>
<th>sentiment</th>
</tr>
</thead>
<tbody>
<tr>
<th>11841</th>
<td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>
<td>1</td>
</tr>
<tr>
<th>19602</th>
<td>OK... so... I really like Kris Kristofferson a...</td>
<td>0</td>
</tr>
<tr>
<th>45519</th>
<td>***SPOILER*** Do not read this, if you think a...</td>
<td>0</td>
</tr>
<tr>
<th>25747</th>
<td>hi for all the people who have seen this wonde...</td>
<td>1</td>
</tr>
<tr>
<th>42642</th>
<td>I recently bought the DVD, forgetting just how...</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fa3e1228a5d50edf">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Introducing-the-Bag-Of-Words-Model">Introducing the Bag-Of-Words Model<a class="anchor-link" href="#Introducing-the-Bag-Of-Words-Model"></a></h2><p>The idea behind the <strong>Bag-Of-Words</strong> is quiet simple</p>
<ol>
<li>We create a vocabulearly of unique tokens- E.g. words from the entire set of documnets</li>
<li>We construct a feature vector from each document that contains the counts of how often each word occurs in a particular document.</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=10eed2eee6dddbfb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Transforming-Words-into-Feature-Vectors">Transforming Words into Feature Vectors<a class="anchor-link" href="#Transforming-Words-into-Feature-Vectors"></a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6bbd9e8ddb297d46">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>In this step, we use CountVectorizer to build a Bag-of-Words representation of a small corpus.
The vectorizer first learns a vocabulary of all unique tokens in the four example sentences (count.vocabulary_).
Then, fit_transform converts each sentence into a row of the documentterm matrix, where each column corresponds to a word in the vocabulary and each entry stores how often that word appears in the sentence.
The result (bag.toarray()) is a numerical matrix that we can feed into machine-learning models.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=5cde56c036153439">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span><span class="s1">'The sun is shining'</span><span class="p">,</span>
     <span class="s1">'The weather is sweet'</span><span class="p">,</span>
     <span class="s1">'The sun is shining, the weather is sweet'</span><span class="p">,</span>
     <span class="s1">'and one and one is two'</span>
     <span class="p">]</span>
<span class="p">)</span>
<span class="n">bag</span> <span class="o">=</span> <span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">count</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=94a11beffeeeb014">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">bag</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[[0 1 0 1 1 0 1 0 0]
 [0 1 0 0 0 1 1 0 1]
 [0 2 0 1 1 1 2 0 1]
 [2 1 2 0 0 0 0 1 0]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=75632a2d41b2a4d2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Raw-term-frequencies">Raw term frequencies<a class="anchor-link" href="#Raw-term-frequencies"></a></h3><p>In the bag-of-words model, <em>raw term frequency</em> for a word is simply the <strong>number of times that word appears in a document</strong>, without any extra scaling or weighting.</p>
<ul>
<li>For each document, we build a vocabulary of all unique tokens (words).</li>
<li>For every word in that vocabulary, we count how many times it occurs in the document.</li>
<li>These counts form the feature vector for the document (one dimension per word).</li>
</ul>
<p>Example:
If the document is:</p>
<blockquote>
<p>"the sun is shining, the weather is sweet"</p>
</blockquote>
<p>and our vocabulary includes <code>["the", "sun", "is", "shining", "weather", "sweet"]</code>, then the raw term frequencies are:</p>
<ul>
<li><code>the</code>  2</li>
<li><code>sun</code>  1</li>
<li><code>is</code>  1</li>
<li><code>shining</code>  1</li>
<li><code>weather</code>  1</li>
<li><code>sweet</code>  1</li>
</ul>
<p>No normalization (like dividing by document length) and no weighting (like TFIDF) is applied here  we are just using <strong>plain counts</strong>.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=13bc3105424be888">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="N-gram-Models-(Unigrams,-Bigrams,-Trigrams)">N-gram Models (Unigrams, Bigrams, Trigrams)<a class="anchor-link" href="#N-gram-Models-(Unigrams,-Bigrams,-Trigrams)"></a></h3><p>In the previous section, we built a <strong>bag-of-words</strong> model using <strong>raw term frequencies</strong>.
That model was based on <strong>unigrams</strong>, i.e. single words.</p>
<p>An <strong>n-gram</strong> is defined as a sequence of <em>n</em> consecutive tokens (usually words) from a text:</p>
<ul>
<li><strong>Unigram (1-gram)</strong>: sequences of length 1<ul>
<li>Example: <code>"the weather is sweet"</code>
 <code>["the", "weather", "is", "sweet"]</code></li>
</ul>
</li>
<li><strong>Bigram (2-gram)</strong>: sequences of length 2<ul>
<li>Example: <code>"the weather is sweet"</code>
 <code>["the weather", "weather is", "is sweet"]</code></li>
</ul>
</li>
<li><strong>Trigram (3-gram)</strong>: sequences of length 3<ul>
<li>Example: <code>"the weather is sweet"</code>
 <code>["the weather is", "weather is sweet"]</code></li>
</ul>
</li>
</ul>
<p>A unigram bag-of-words model ignores word order and only uses <strong>individual word counts</strong> as features.
By contrast, <strong>n-gram models</strong> (with n  2) can capture short-range context and common phrases, such as:</p>
<ul>
<li>sentiment phrases like <code>"not good"</code>, <code>"very bad"</code>, <code>"really great"</code></li>
<li>named entities like <code>"New York"</code>, <code>"Los Angeles"</code></li>
</ul>
<p>This makes n-gram features particularly useful in <strong>sentiment analysis</strong> and other NLP tasks where local word order carries important meaning.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=dc9c377f5ffea187">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Assessing-Word-Relevancy-with-TF%E2%80%93IDF">Assessing Word Relevancy with TFIDF<a class="anchor-link" href="#Assessing-Word-Relevancy-with-TF%E2%80%93IDF"></a></h3><p>Bag-of-words and n-gram models give us <strong>raw term frequencies</strong> (how many times each word or phrase appears in a document). However, frequent words are not always informative. For example, words like the, is, or movie may appear in almost every review, regardless of sentiment.</p>
<p>To capture <strong>how relevant a word is for a specific document</strong>, we use <strong>TFIDF (Term FrequencyInverse Document Frequency)</strong>.</p>
<ul>
<li><p><strong>Term Frequency (TF)</strong>
Measures how often a term appears in a single document.
Higher TF  the term is more important <em>within that document</em>.</p>
</li>
<li><p><strong>Inverse Document Frequency (IDF)</strong>
Measures how common or rare a term is across the whole collection of documents.</p>
<ul>
<li>Terms that appear in <strong>many</strong> documents (e.g., the) get a <strong>low</strong> IDF.</li>
<li>Terms that appear in <strong>fewer</strong> documents (e.g., excellent, terrible) get a <strong>higher</strong> IDF.</li>
</ul>
</li>
<li><p><strong>TFIDF score</strong>
TFIDF combines these two ideas:</p>
<blockquote>
<p><strong>TFIDF(term, document) = TF(term in this document)  IDF(term over all documents)</strong></p>
</blockquote>
<p>Intuition:</p>
<ul>
<li>A term gets a <strong>high TFIDF</strong> score if<ul>
<li>it appears frequently in this document (<strong>high TF</strong>), and</li>
<li>it does <strong>not</strong> appear in most other documents (<strong>high IDF</strong>).</li>
</ul>
</li>
<li>Very common words across the corpus get <strong>low TFIDF</strong> scores, even if they appear often in a document.</li>
</ul>
</li>
</ul>
<p>In practice, TFIDF helps the model focus on <strong>discriminative words</strong>, such as excellent, boring, waste, or masterpiece, which are more useful for tasks like <strong>sentiment analysis</strong> than very common function words.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cc0be3efa325fe29">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Scikit-Learn library implememts yet another transformer, the <em>TfidfTransformer</em> class, which takes in raw term frequencies from the <em>CountVectorize</em> class as input and transforms them into tf-idf</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=db337dba274407eb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">TfidfTransformer</span>

<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">'l2'</span><span class="p">,</span> <span class="n">smooth_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># counts from CountVectorizer</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>

<span class="c1"># transform counts  tfidf</span>
<span class="n">tfidf_matrix</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tfidf_matrix</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[[0.   0.38 0.   0.57 0.57 0.   0.46 0.   0.  ]
 [0.   0.38 0.   0.   0.   0.57 0.46 0.   0.57]
 [0.   0.46 0.   0.35 0.35 0.35 0.56 0.   0.35]
 [0.66 0.17 0.66 0.   0.   0.   0.   0.33 0.  ]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=82cdab0a41432e54">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Cleaning-Text-Data">Cleaning Text Data<a class="anchor-link" href="#Cleaning-Text-Data"></a></h2><p>Before we build our Bag-of-Words and TFIDF models, we first need to clean the raw text.
Real-world reviews contain a lot of noise such as HTML tags, punctuation, numbers,
and inconsistent casing. If we feed this directly into the model, the vocabulary
becomes messy and the model wastes capacity on useless tokens.</p>
<p>In this project, our basic text-cleaning pipeline will:</p>
<ol>
<li><p><strong>Normalize the text</strong></p>
<ul>
<li>Convert everything to lowercase</li>
<li>Remove HTML tags and line breaks</li>
</ul>
</li>
<li><p><strong>Remove unwanted characters</strong></p>
<ul>
<li>Strip punctuation, numbers, and other non-word symbols</li>
<li>Collapse multiple spaces into a single space</li>
</ul>
</li>
<li><p><strong>Tokenize and filter</strong></p>
<ul>
<li>Split the cleaned text into individual tokens (words)</li>
<li>Optionally remove stop words (very common words like <em>the</em>, <em>is</em>, <em>and</em>)</li>
</ul>
</li>
</ol>
<p>After this preprocessing step, each review is reduced to a cleaner sequence of words,
which we then feed into the Bag-of-Words / TFIDF pipeline.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ba40074a20dec3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>We will now remove all punctuations marks except for emoticon characters, such as :), since those are useful for sentiment analysis. To accomplish this task, we will use the Python's <strong>Regular Expression (regex)</strong> library, <em>re</em></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=432152cdbf05bbc7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="k">def</span><span class="w"> </span><span class="nf">preprocessor</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># remove HTML tags</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'&lt;[^&gt;]+&gt;'</span><span class="p">,</span> <span class="s1">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># extract emoticons like :) ;-) :D etc.</span>
    <span class="n">emoticons</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">'(?::|;|=)(?:-)?(?:\)|\(|D|P)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># remove non-word chars, lowercase, then append emoticons (without '-')</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[\W]+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">emoticons</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'-'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">text</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d093a7e40b130e43">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Note:-Regex-backslashes-and-SyntaxWarning:-invalid-escape-sequence">Note: Regex backslashes and <code>SyntaxWarning: invalid escape sequence</code><a class="anchor-link" href="#Note:-Regex-backslashes-and-SyntaxWarning:-invalid-escape-sequence"></a></h3><p><strong>Whats happening?</strong></p>
<ul>
<li>Our regex patterns contain things like <code>\)</code> and <code>\W</code>.<ul>
<li>In <strong>regex</strong>, these are valid:<ul>
<li><code>\)</code> means literal <code>)</code></li>
<li><code>\W</code> means non-word character</li>
</ul>
</li>
</ul>
</li>
<li>But in <strong>normal Python strings</strong>, a backslash starts an <em>escape sequence</em> (like <code>\n</code>, <code>\t</code>).<ul>
<li><code>\)</code> and <code>\W</code> are <strong>not</strong> valid Python string escapes.</li>
<li>Python still runs the code, but it shows warnings like:
<code>SyntaxWarning: invalid escape sequence '\)'</code> and <code>'\W'</code>.</li>
</ul>
</li>
</ul>
<p><strong>Why this matters</strong></p>
<ul>
<li>The regex logic is correct, but the way its written as a Python string is noisy.</li>
<li>These warnings can hide real problems later, so its good practice to fix them.</li>
</ul>
<p><strong>Fix</strong></p>
<ul>
<li>Make regex patterns <strong>raw strings</strong> so backslashes are passed directly to the regex engine.</li>
<li>Use the <code>r""</code> prefix:</li>
</ul>
<div class="highlight"><pre><span></span><span class="c1"># bad (will raise SyntaxWarning)</span>
<span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">'(?::|;|=)(?:-)?(?:\)|$begin:math:text$\|D\|P\)</span><span class="se">\'</span><span class="s1">\, text\)</span>
<span class="n">re</span>\<span class="o">.</span><span class="n">sub</span>\<span class="p">(</span>\<span class="s1">'\[</span><span class="se">\\</span><span class="s1">W\]\+</span><span class="se">\'</span><span class="s1">\, </span><span class="se">\'</span><span class="s1"> </span><span class="se">\'</span><span class="s1">\, text\.lower\(\)\)</span>

\<span class="c1"># good \(raw strings\, no warnings\)</span>
<span class="n">re</span>\<span class="o">.</span><span class="n">findall</span>\<span class="p">(</span><span class="n">r</span>\<span class="s1">'\(\?\:\:\|\;\|\=\)\(\?\:\-\)\?\(\?\:$end:math:text$|\(|D|P)'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
<span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[\W]+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=693373a7b0d0cc9b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># lets confirm that our preprocessor works correctly</span>
<span class="n">preprocessor</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">'review'</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="mi">50</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[10]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'and i suggest that you go see it before you judge  '</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=c3f78ebbd20211aa">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># Another one</span>
<span class="n">preprocessor</span><span class="p">(</span><span class="s2">"&lt;/a&gt; This :) is :( a test :-)!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[11]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>' this is a test  :) :( :)'</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=bce96ec0f629f6bc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># Now lets apply our preprocessor function to all the movie reviews in our DataFrame</span>
<span class="n">df</span><span class="p">[</span><span class="s1">'review'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'review'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=7247c201b045050b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Cleaning-Text-Data">Cleaning Text Data<a class="anchor-link" href="#Cleaning-Text-Data"></a></h2><p>Before building our Bag-of-Words and TFIDF models, we first normalize the raw text.</p>
<p>Our <code>preprocessor</code> function does three main things:</p>
<ol>
<li><p><strong>Remove HTML tags and punctuation</strong>
We strip out HTML markup (e.g. <code>&lt;br /&gt;</code>) and most punctuation characters so that they do not become separate words in our vocabulary.</p>
</li>
<li><p><strong>Preserve emoticons</strong>
Simple emoticons such as <code>:)</code>, <code>:(</code>, <code>:-)</code> are extracted using a regular expression and re-attached to the cleaned text.
These patterns often carry strong sentiment and are therefore useful features.</p>
</li>
<li><p><strong>Lowercase everything</strong>
We convert the text to lowercase so that words like <code>Good</code>, <code>GOOD</code>, and <code>good</code> are treated as the same token.</p>
</li>
</ol>
<p>After preprocessing, each review is a cleaner, more uniform string that is easier to tokenize and vectorize. This reduces noise in the feature space and helps the classifier focus on actual sentiment patterns instead of formatting differences.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=8d0d7b166bfee71e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="n">tokenizer</span><span class="p">(</span><span class="s1">'runners like running and thus they run'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[13]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['runners', 'like', 'running', 'and', 'thus', 'they', 'run']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=28077056c780dd49">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Using-NLTK-(Natural-Language-Toolkit)">Using NLTK (Natural Language Toolkit)<a class="anchor-link" href="#Using-NLTK-(Natural-Language-Toolkit)"></a></h2><p>In this section we introduce <strong>NLTK  Natural Language Toolkit</strong>, a popular Python library for basic NLP tasks.</p>
<p>At a high level, NLTK gives us:</p>
<ul>
<li><p><strong>Tokenization</strong>
Functions to split raw text into sentences or words.
Example:
<code>"This is a test."</code>  <code>["This", "is", "a", "test", "."]</code></p>
</li>
<li><p><strong>Stop word lists</strong>
Built-in lists of very common words such as <em>the, and, is</em> that usually do not carry much meaning for tasks like sentiment analysis.
We can remove these tokens to reduce noise.</p>
</li>
<li><p><strong>Stemming and lemmatization</strong>
Tools to reduce different word forms to a common base:</p>
<ul>
<li><em>Stemming</em> (e.g. Porter stemmer) cuts words down to a root:
<code>"running", "runs", "ran"</code>  <code>"run"</code></li>
<li><em>Lemmatization</em> uses vocabulary and grammar rules to map words to a canonical form:
<code>"mice"</code>  <code>"mouse"</code>, <code>"better"</code>  <code>"good"</code></li>
</ul>
</li>
</ul>
<p>In our IMDB sentiment project we mainly use NLTK to:</p>
<ol>
<li>Build a <strong>smarter tokenizer</strong> than just <code>text.split()</code>.</li>
<li>Optionally <strong>remove stop words</strong> that do not help the classifier.</li>
<li>Optionally <strong>stem</strong> words so that different forms (e.g. <em>run, running, runs</em>) are treated as the same feature.</li>
</ol>
<p>This improves our Bag-of-Words and TFIDF representations, because the model focuses on the core meaning of the text instead of superficial differences in capitalization, punctuation, or verb forms.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8e2e56c61a140795">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Porter-Stemmer-Algorithm">Porter Stemmer Algorithm<a class="anchor-link" href="#Porter-Stemmer-Algorithm"></a></h3><p>The <strong>Porter stemmer</strong> is a classic rule-based algorithm for <strong>stemming</strong> English words.
Stemming means reducing different word forms to a simpler, common <strong>stem</strong> by stripping off
frequent suffixes.</p>
<p>The Porter stemmer works in several steps, each applying rules such as:</p>
<ul>
<li><code>caresses  caress</code> (remove <em>es</em>)</li>
<li><code>ponies  poni</code> (replace <em>ies</em> with <em>i</em>)</li>
<li><code>caressed  caress</code> (remove <em>ed</em>)</li>
<li><code>hopping  hop</code>, <code>hoped  hope</code></li>
<li><code>relational  relat</code>, <code>conditional  condit</code></li>
</ul>
<p>The resulting stems are not always valid English words (e.g. <em>relat</em>, <em>studi</em>), but they are
<strong>consistent</strong>, which is what we need for Bag-of-Words / TFIDF features.</p>
<p>In the IMDB sentiment project we use the Porter stemmer to:</p>
<ul>
<li>collapse different inflected forms of a word (e.g. <em>run, runs, running, ran</em>) into one stem,</li>
<li>reduce the size of the vocabulary,</li>
<li>make the model focus on the underlying concepts rather than small spelling variations.</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=184fd52a7656e342">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nltk.stem.porter</span><span class="w"> </span><span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="n">porter</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
<span class="k">def</span><span class="w"> </span><span class="nf">tokenizer_porter</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">porter</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
<span class="n">tokenizer_porter</span><span class="p">(</span><span class="s1">'runners like running and thus they run'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[14]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['runner', 'like', 'run', 'and', 'thu', 'they', 'run']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=75fd00776f662bde">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Stop-Word-Removal">Stop-Word Removal<a class="anchor-link" href="#Stop-Word-Removal"></a></h3><p><strong>Stop words</strong> are very common words such as <em>the, a, an, is, was, and, or, to, of, in</em> that usually
do not carry much content information. In a Bag-of-Words model with <strong>raw</strong> or <strong>normalized term
frequencies (tf)</strong> these words:</p>
<ul>
<li>appear in almost every document,</li>
<li>produce very high counts,</li>
<li>increase the dimensionality of the feature space,</li>
<li>and add little useful signal for classification.</li>
</ul>
<p>Therefore, stop-word removal is especially helpful when we work with tf-based features.</p>
<p>When we use <strong>TFIDF</strong>, extremely frequent words automatically receive a low weight because their
inverse document frequency (IDF) is small. In that case, stop-word removal is less critical but
still useful to reduce noise and vocabulary size.</p>
<p>For sentiment analysis we usually <em>do not</em> remove negation words such as <em>not, no, never</em>, since
they can completely change the polarity of a sentence (e.g. good vs not good). We typically
start from a standard stop-word list and then customize it to keep important tokens like negations.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=c57dfc6d0474e24c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">ENGLISH_STOP_WORDS</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ENGLISH_STOP_WORDS</span><span class="p">))</span>
<span class="nb">list</span><span class="p">(</span><span class="n">ENGLISH_STOP_WORDS</span><span class="p">)[:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>318
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[15]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>['own',
 'we',
 'else',
 'then',
 'whatever',
 'yourself',
 'mostly',
 'who',
 'often',
 'namely',
 'those',
 'also',
 'front',
 'which',
 'sincere',
 'few',
 'fill',
 'an',
 'forty',
 'enough']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b110d43be1f8e129">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Stop-Word-Removal">Stop-Word Removal<a class="anchor-link" href="#Stop-Word-Removal"></a></h2><p><strong>Stop words</strong> are very common words such as <em>the, a, an, is, was, and, or, to, of</em> that usually do not carry much content information.</p>
<p>In a Bag-of-Words model with <strong>raw or normalized term frequencies (tf)</strong> these words:</p>
<ul>
<li>appear in almost every document,</li>
<li>produce very high counts,</li>
<li>increase the dimensionality of the feature space, and</li>
<li>add little useful signal for classification.</li>
</ul>
<p>Because of that, <strong>stop-word removal</strong> is especially helpful when we work with tf-based features.</p>
<p>When we use <strong>TFIDF</strong>, extremely frequent words automatically receive a low weight because their inverse document frequency (IDF) is small. In that case, stop-word removal is less critical, but it still helps reduce noise and vocabulary size.</p>
<p>For <strong>sentiment analysis</strong> we usually <strong>do not</strong> remove negation words such as <em>not, no, never</em>, since they can completely change the polarity of a sentence (e.g. good vs not good). We typically start from a standard stop-word list and then customize it to keep important tokens like negations.</p>
<hr/>
<h3 id="Using-Stop-Words-in-This-Project">Using Stop Words in This Project<a class="anchor-link" href="#Using-Stop-Words-in-This-Project"></a></h3><p>Instead of using NLTKs stop words, we use the list that comes <strong>built in with scikit-learn</strong>:</p>
<p>from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS</p>
<h1 id="start-from-scikit-learn's-default-English-stop-words">start from scikit-learn's default English stop words<a class="anchor-link" href="#start-from-scikit-learn's-default-English-stop-words"></a></h1><p>print(len(ENGLISH_STOP_WORDS))
list(ENGLISH_STOP_WORDS)[:20]</p>
<p>We can also customize this list, for example to keep negation words:
custom_stopwords = ENGLISH_STOP_WORDS.difference({'not', 'no', 'never'})</p>
<p>Then we plug this into our tokenizer + stemmer:
from nltk.stem.porter import PorterStemmer
porter = PorterStemmer()</p>
<p>def tokenizer_porter_no_stop(text):
return [
porter.stem(word)
for word in text.split()
if word.lower() not in custom_stopwords
]
This gives us stemmed tokens with most uninformative words removed, but keeps crucial negations.</p>
<hr/>
<h3 id="Why-scikit-learn-stop-words-worked-but-NLTK-stop-words-did-not">Why scikit-learn stop words worked but NLTK stop words did not<a class="anchor-link" href="#Why-scikit-learn-stop-words-worked-but-NLTK-stop-words-did-not"></a></h3><p>When we tried to use NLTK:
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stop = stopwords.words('english')</p>
<p>we saw errors like:
	SSL: CERTIFICATE_VERIFY_FAILED
	LookupError: Resource 'stopwords' not found</p>
<p>What happened:</p>
<ul>
<li>nltk.download('stopwords') tries to download the stop-word corpus over HTTPS.</li>
<li>On this Mac, the HTTPS request failed because of a certificate verification issue (CERTIFICATE_VERIFY_FAILED).</li>
<li>As a result, the stopwords data never got saved to the local nltk_data folder.</li>
<li>Later, stopwords.words('english') looked for that file, couldnt find it, and raised a LookupError.</li>
</ul>
<p>In contrast, scikit-learns ENGLISH_STOP_WORDS:
	is bundled directly inside the scikit-learn package,
	does not require any download or internet access,
	so it works immediately with no SSL or lookup errors.</p>
<p>Functionally, both NLTK and scikit-learn provide lists of common English stop words.
For this IMDB sentiment project, using scikit-learns built-in list is perfectly fine and avoids the NLTK download issues on this machine.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a48898394b949143">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Training-a-Logistic-Regression-Model-for-Document-Classification">Training a Logistic Regression Model for Document Classification<a class="anchor-link" href="#Training-a-Logistic-Regression-Model-for-Document-Classification"></a></h2><p>In this section we train a <strong>logistic regression</strong> classifier on the IMDB
movie reviews using a Bag-of-Words / TFIDF representation.</p>
<h3 id="Why-logistic-regression?">Why logistic regression?<a class="anchor-link" href="#Why-logistic-regression?"></a></h3><p>For binary text classification (positive vs negative review), logistic
regression is a strong baseline:</p>
<ul>
<li>It works very well with <strong>high-dimensional sparse features</strong> (like
bag-of-words).</li>
<li>The model is <strong>linear</strong>, easy to regularize, and relatively fast to train.</li>
<li>The output is a <strong>probability</strong> for each class, which is easy to interpret.</li>
</ul>
<h3 id="Train-/-test-split">Train / test split<a class="anchor-link" href="#Train-/-test-split"></a></h3><p>We already built <code>movie_data.csv</code> with 50,000 reviews and labels:</p>
<ul>
<li>25,000 reviews for training</li>
<li>25,000 reviews for testing</li>
</ul>
<p>We extract:</p>
<ul>
<li><code>X</code> = reviews (raw text)</li>
<li><code>y</code> = sentiment labels (0 = negative, 1 = positive)</li>
</ul>
<p>Then we slice the first 25k as train and the rest as test, following the
textbook.</p>
<h3 id="Pipeline-+-GridSearchCV">Pipeline + GridSearchCV<a class="anchor-link" href="#Pipeline-+-GridSearchCV"></a></h3><p>We build a scikit-learn <code>Pipeline</code> with two steps:</p>
<ol>
<li><p><strong>Vectorizer</strong> (<code>TfidfVectorizer</code>):</p>
<ul>
<li>converts raw text  token counts  TFIDF weights</li>
<li>we will try different options for:<ul>
<li><code>ngram_range</code> (unigrams vs bigrams)</li>
<li><code>stop_words</code> (use our stopwords or None)</li>
<li><code>tokenizer</code> (simple split vs Porter stemmer)</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Classifier</strong> (<code>LogisticRegression</code>):</p>
<ul>
<li>with L2 regularization</li>
<li>hyperparameter <code>C</code> controls regularization strength
(small <code>C</code> = stronger regularization).</li>
</ul>
</li>
</ol>
<p>We use <strong>GridSearchCV</strong> with 5-fold stratified cross-validation to search
over combinations of:</p>
<ul>
<li>BoW/TFIDF parameters (ngrams, stop words, tokenizer, etc.)</li>
<li>Logistic regression parameters (<code>C</code>, penalty)</li>
</ul>
<p>The grid has two dictionaries:</p>
<ol>
<li>Standard TFIDF settings (<code>use_idf=True</code>, <code>norm='l2'</code>).</li>
<li>"Raw tf" style settings with <code>use_idf=False</code>, <code>smooth_idf=False</code>,
<code>norm=None</code>.</li>
</ol>
<p>This mirrors the idea from the chapter: <strong>compare models based on pure term
frequency vs TFIDF</strong>.</p>
<p>We run <code>GridSearchCV</code> with:</p>
<ul>
<li><code>scoring='accuracy'</code></li>
<li><code>cv=5</code></li>
<li><code>n_jobs=-1</code> (use all cores)</li>
<li><code>verbose=2</code> (show progress)</li>
</ul>
<p>After the search:</p>
<ul>
<li><code>gs_lr_tfidf.best_params_</code> gives the best combination of settings.</li>
<li><code>gs_lr_tfidf.best_score_</code> gives mean CV accuracy.</li>
<li><code>gs_lr_tfidf.best_estimator_</code> is the final trained pipeline.</li>
<li>We then evaluate on the 25k held-out test reviews to get <strong>test accuracy</strong>.</li>
</ul>
<p>The key takeaway: with a well-tuned logistic regression + TFIDF, we can reach
~90% accuracy on IMDB sentiment classification.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4b73bedc4bbfb43a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">TfidfVectorizer</span>


<span class="c1"># 1. Load data (if you don't already have df in memory)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"movie_data.csv"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span>  <span class="c1"># review, sentiment</span>

<span class="c1"># 25k train / 25k test split as in the book</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="mi">24999</span><span class="p">,</span> <span class="s1">'review'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="mi">24999</span><span class="p">,</span> <span class="s1">'sentiment'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="n">X_test</span>  <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">25000</span><span class="p">:,</span> <span class="s1">'review'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_test</span>  <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">25000</span><span class="p">:,</span> <span class="s1">'sentiment'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ca33f9879bf52083">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># 2. Vectorizer + Logistic Regression pipeline</span>


<span class="c1"># if you have your own preprocessor/tokenizers, import/define them here</span>
<span class="c1"># from your earlier cells:</span>
<span class="c1"># - preprocessor (clean HTML, emoticons, lowercasing, etc.)</span>
<span class="c1"># - tokenizer (simple split with optional cleaning)</span>
<span class="c1"># - tokenizer_porter (uses PorterStemmer)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">ENGLISH_STOP_WORDS</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">ENGLISH_STOP_WORDS</span>  <span class="c1"># our base stop-word list</span>

<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span>
    <span class="n">strip_accents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>          <span class="c1"># we already handle casing in preprocessor</span>
    <span class="n">preprocessor</span><span class="o">=</span><span class="n">preprocessor</span> <span class="c1"># your custom preprocessor function</span>
<span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">solver</span><span class="o">=</span><span class="s2">"liblinear"</span>        <span class="c1"># works well for small/medium text problems</span>
<span class="p">)</span>

<span class="n">lr_tfidf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">"vect"</span><span class="p">,</span> <span class="n">tfidf</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">"clf"</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=62b37e811c5091da">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># 3. Parameter grid</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">"vect__ngram_range"</span><span class="p">:</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>   <span class="c1"># unigrams</span>
        <span class="s2">"vect__stop_words"</span><span class="p">:</span>   <span class="p">[</span><span class="n">stop</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">"vect__tokenizer"</span><span class="p">:</span>    <span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">tokenizer_porter</span><span class="p">],</span>
        <span class="s2">"clf__penalty"</span><span class="p">:</span>       <span class="p">[</span><span class="s2">"l2"</span><span class="p">],</span>
        <span class="s2">"clf__C"</span><span class="p">:</span>             <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">"vect__ngram_range"</span><span class="p">:</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
        <span class="s2">"vect__stop_words"</span><span class="p">:</span>   <span class="p">[</span><span class="n">stop</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">"vect__tokenizer"</span><span class="p">:</span>    <span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">tokenizer_porter</span><span class="p">],</span>
        <span class="s2">"vect__use_idf"</span><span class="p">:</span>      <span class="p">[</span><span class="kc">False</span><span class="p">],</span>
        <span class="s2">"vect__norm"</span><span class="p">:</span>         <span class="p">[</span><span class="kc">None</span><span class="p">],</span>
        <span class="s2">"clf__penalty"</span><span class="p">:</span>       <span class="p">[</span><span class="s2">"l2"</span><span class="p">],</span>
        <span class="s2">"clf__C"</span><span class="p">:</span>             <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4985d09bd644629a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Regularization-(short-recap)">Regularization (short recap)<a class="anchor-link" href="#Regularization-(short-recap)"></a></h3><p>In high-dimensional text data, a logistic regression model can easily overfit:
it can give very large weights to some words or n-grams that only appear in the
training set. <strong>Regularization</strong> is a way to control this complexity.</p>
<p>We add a penalty on the size of the weight vector ( w ) to the loss
function:</p>
<ul>
<li><strong>L2 regularization (ridge)</strong> uses ( \lambda \sum_j w_j^2 ).
This keeps many weights <strong>small but non-zero</strong>, which works very well with
Bag-of-Words / TFIDF features.</li>
<li><strong>L1 regularization (lasso)</strong> uses ( \lambda \sum_j |w_j| ).
This encourages <strong>sparse</strong> solutions where many weights are exactly zero,
which acts like an automatic feature selection.</li>
</ul>
<p>In scikit-learns <code>LogisticRegression</code> the strength of regularization is
controlled by the parameter <strong>C</strong>, which is the <strong>inverse</strong> of (\lambda):</p>
<ul>
<li>small <code>C</code>  <strong>strong</strong> regularization (simpler model),</li>
<li>large <code>C</code>  <strong>weak</strong> regularization (more flexible model).</li>
</ul>
<p>In this chapter we tune <code>C</code> using cross-validation to find a good balance
between <strong>fitting the training data</strong> and <strong>generalizing to unseen reviews</strong>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=6deb53686245989b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># 4. GridSearchCV (5-fold stratified CV)</span>

<span class="n">gs_lr_tfidf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">lr_tfidf</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">"accuracy"</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"CV Accuracy: </span><span class="si">%.3f</span><span class="s2">"</span> <span class="o">%</span> <span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Best params:"</span><span class="p">,</span> <span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Fitting 5 folds for each of 24 candidates, totalling 120 fits
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'a', 'describe', 'less', 'be', 'sixty', 'only', 'side', 'its', 'cant', 'otherwise', 'hereby', 'anyone', 'somehow', 'elsewhere', 'several', 'whenever', 'thick', 'he', 'because', 'back', 'due', 'none', 'two', 'thin', 'nevertheless', 'himself', 'neither', 'thereupon', 'so', 'made', 'becoming', 'else', 'name', 'another', 'after', 'some', 'last', 'noone', 'will', 'without', 'out', 'her', 'find', 'who', 'go', 'yourselves', 'done', 'have', 'and', 'is', 'even', 'could', 'too', 'somewhere', 'alone', 'are', 'on', 'afterwards', 'below', 'top', 'beyond', 'latter', 'anywhere', 'anyhow', 'cry', 'now', 'former', 'every', 'fifteen', 'bottom', 'nothing', 'also', 'mill', 'detail', 'into', 'part', 'seems', 'least', 'hers', 'toward', 'interest', 'me', 'amongst', 'should', 'indeed', 'five', 'ten', 'whom', 'except', 'eleven', 'meanwhile', 'fire', 'therefore', 'one', 'per', 'give', 'his', 'this', 'than', 'next', 'empty', 'whereafter', 'yourself', 'whence', 'whereby', 'there', 'hereupon', 'yours', 'wherein', 'couldnt', 'my', 'during', 'together', 'others', 'being', 'still', 'seem', 'it', 'serious', 'un', 'off', 'from', 'enough', 'eg', 'might', 'at', 'how', 'amount', 'third', 'along', 'anything', 'ours', 'may', 'de', 'take', 'by', 'has', 'front', 'can', 'was', 'both', 'etc', 'very', 'themselves', 'if', 'same', 'seeming', 'the', 'their', 'ever', 'before', 'further', 'whether', 'our', 'nor', 'everywhere', 'keep', 'move', 'inc', 'through', 'with', 'beside', 'please', 'up', 'these', 'perhaps', 'call', 'since', 'among', 'whatever', 'until', 'almost', 'thereafter', 'must', 'where', 'system', 'itself', 'what', 'all', 'mostly', 'i', 'such', 'hundred', 'but', 'hasnt', 'someone', 'they', 'sincere', 'full', 'then', 'wherever', 'most', 'besides', 'get', 'mine', 'found', 'twenty', 'which', 'above', 'moreover', 'therein', 'thereby', 'herself', 'more', 'us', 'co', 'whose', 'other', 'again', 'con', 'not', 'we', 'myself', 'to', 'upon', 'amoungst', 'via', 're', 'whither', 'however', 'that', 'twelve', 'rather', 'much', 'beforehand', 'either', 'sometimes', 'eight', 'them', 'would', 'nowhere', 'fill', 'why', 'were', 'nine', 'ie', 'you', 'am', 'fifty', 'or', 'under', 'around', 'put', 'herein', 'here', 'something', 'whereas', 'towards', 'hence', 'whole', 'see', 'ltd', 'had', 'four', 'thence', 'often', 'few', 'everything', 'onto', 'as', 'never', 'your', 'she', 'whereupon', 'own', 'him', 'any', 'hereafter', 'already', 'become', 'between', 'in', 'whoever', 'behind', 'of', 'cannot', 'anyway', 'within', 'many', 'been', 'becomes', 'against', 'forty', 'three', 'show', 'down', 'though', 'across', 'bill', 'namely', 'about', 'although', 'when', 'over', 'do', 'became', 'those', 'six', 'once', 'each', 'throughout', 'yet', 'sometime', 'first', 'formerly', 'seemed', 'an', 'for', 'everyone', 'no', 'while', 'latterly', 'nobody', 'ourselves', 'always', 'thru', 'thus', 'well'}), vect__tokenizer=&lt;function tokenizer at 0x10efe3b00&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'someone', 'within', 'over', 'also', 'under', 'further', 'nine', 'were', 'least', 'call', 'full', 'formerly', 'beyond', 'still', 'since', 'then', 'three', 'cry', 'please', 'becoming', 'how', 'against', 'around', 'whose', 'nothing', 'eight', 'here', 'why', 'below', 'six', 'all', 'seem', 're', 'ie', 'themselves', 'without', 'de', 'whole', 'always', 'myself', 'rather', 'only', 'upon', 'itself', 'becomes', 'should', 'into', 'thru', 'him', 'whereby', 'get', 'us', 'them', 'but', 'could', 'at', 'seems', 'amount', 'might', 'done', 'this', 'beside', 'bottom', 'herein', 'except', 'couldnt', 'beforehand', 'detail', 'never', 'moreover', 'more', 'seeming', 'that', 'almost', 'whoever', 'whether', 'everyone', 'hereafter', 'otherwise', 'thus', 'empty', 'indeed', 'their', 'system', 'as', 'therein', 'my', 'was', 'nobody', 'sometime', 'fifty', 'latterly', 'go', 'will', 'find', 'me', 'twelve', 'yours', 'who', 'am', 'together', 'from', 'what', 'which', 'do', 'whither', 'five', 'because', 'up', 'would', 'during', 'i', 'anywhere', 'be', 'above', 'thereafter', 'many', 'whatever', 'a', 'any', 'cannot', 'put', 'towards', 'others', 'take', 'give', 'hasnt', 'your', 'anything', 'the', 'though', 'sincere', 'thin', 'whereupon', 'third', 'made', 'former', 'meanwhile', 'it', 'have', 'so', 'back', 'ten', 'mostly', 'etc', 'inc', 'toward', 'they', 'amoungst', 'first', 'she', 'next', 'eg', 'something', 'about', 'four', 'much', 'both', 'twenty', 'afterwards', 'when', 'between', 'see', 'there', 'alone', 'yourselves', 'hence', 'fifteen', 'elsewhere', 'seemed', 'his', 'fire', 'every', 'eleven', 'if', 'some', 'by', 'perhaps', 'anyhow', 'top', 'on', 'keep', 'somewhere', 'whom', 'we', 'or', 'same', 'two', 'among', 'in', 'very', 'whenever', 'fill', 'our', 'had', 'become', 'side', 'serious', 'wherein', 'nevertheless', 'therefore', 'few', 'noone', 'move', 'now', 'neither', 'thence', 'too', 'latter', 'those', 'anyway', 'is', 'once', 'mine', 'describe', 'well', 'can', 'less', 'whence', 'of', 'co', 'himself', 'through', 'onto', 'last', 'un', 'amongst', 'may', 'has', 'thereby', 'else', 'after', 'per', 'must', 'show', 'not', 'however', 'whereafter', 'being', 'con', 'most', 'somehow', 'via', 'mill', 'herself', 'own', 'cant', 'behind', 'until', 'along', 'are', 'hundred', 'to', 'besides', 'these', 'other', 'none', 'down', 'yourself', 'again', 'before', 'name', 'out', 'nor', 'found', 'off', 'namely', 'sixty', 'her', 'due', 'its', 'hereupon', 'throughout', 'no', 'each', 'enough', 'became', 'he', 'an', 'while', 'thereupon', 'wherever', 'one', 'bill', 'although', 'part', 'thick', 'and', 'hereby', 'even', 'everything', 'sometimes', 'such', 'across', 'yet', 'already', 'ltd', 'than', 'interest', 'several', 'been', 'you', 'often', 'nowhere', 'everywhere', 'ours', 'another', 'ever', 'ourselves', 'for', 'where', 'front', 'with', 'either', 'whereas', 'anyone', 'forty', 'hers'}), vect__tokenizer=&lt;function tokenizer at 0x10f48fb00&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'less', 'once', 'anywhere', 'none', 'during', 'never', 'found', 'five', 'always', 'i', 'due', 'very', 'becoming', 'beforehand', 'much', 'now', 'done', 'while', 'ltd', 'along', 'eleven', 'it', 'etc', 'who', 'couldnt', 'keep', 'a', 'alone', 'hereupon', 'yourself', 'hers', 'we', 'twelve', 'hence', 'besides', 'hereafter', 'if', 'call', 'his', 'an', 'several', 'among', 'hundred', 'whereafter', 'bottom', 'six', 'those', 'he', 'therefore', 'up', 'together', 'most', 'that', 'yourselves', 'though', 'twenty', 'therein', 'whose', 'meanwhile', 'first', 'inc', 'indeed', 'into', 'except', 'detail', 'below', 'describe', 'whenever', 'themselves', 'thence', 'although', 'them', 'formerly', 'again', 'anyway', 'whither', 'wherever', 'upon', 'itself', 'herein', 'there', 'own', 'nine', 'against', 'been', 'myself', 'same', 'become', 'somehow', 'yours', 'last', 'forty', 'fifty', 'could', 'thereupon', 'give', 'above', 'least', 'at', 'system', 'be', 'eg', 'see', 'three', 'cry', 'noone', 'than', 'few', 'per', 'must', 'amongst', 'she', 'please', 'seeming', 'seemed', 'thin', 'some', 'out', 'am', 'already', 'whereas', 'thru', 'because', 'are', 'from', 'when', 'often', 'de', 'these', 'mill', 'all', 'made', 'without', 'as', 'take', 'co', 'for', 'anyhow', 'via', 'another', 'since', 'its', 'cannot', 'either', 'or', 'whence', 'their', 'why', 'fill', 'mostly', 'neither', 'by', 'put', 'sometime', 'someone', 'is', 'yet', 'somewhere', 'hereby', 'also', 'would', 'ten', 'else', 'whatever', 'still', 'go', 'to', 'the', 'not', 'something', 'which', 'sincere', 'with', 'her', 'con', 'whom', 'any', 'around', 'empty', 'nobody', 'many', 'moreover', 'in', 'interest', 'whereupon', 'nowhere', 'four', 'thereby', 'however', 'our', 'fire', 'within', 'have', 'herself', 'mine', 'latter', 'thus', 'nevertheless', 'latterly', 'whereby', 'next', 're', 'off', 'wherein', 'even', 'whoever', 'beside', 'two', 'seems', 'might', 'others', 'became', 'throughout', 'back', 'us', 'anyone', 'un', 'himself', 'everywhere', 'here', 'anything', 'ours', 'name', 'well', 'third', 'were', 'afterwards', 'every', 'until', 'how', 'they', 'part', 'ever', 'has', 'such', 'top', 'this', 'my', 'no', 'will', 'ie', 'but', 'both', 'onto', 'almost', 'nothing', 'further', 'get', 'side', 'toward', 'whole', 'thick', 'eight', 'on', 'nor', 'sometimes', 'show', 'beyond', 'only', 'over', 'through', 'whether', 'what', 'becomes', 'former', 'each', 'cant', 'perhaps', 'where', 'enough', 'namely', 'other', 'do', 'may', 'had', 'hasnt', 'me', 'full', 'otherwise', 'about', 'one', 'should', 'thereafter', 'fifteen', 'after', 'down', 'find', 'sixty', 'more', 'across', 'too', 'move', 'behind', 'so', 'everything', 'serious', 'front', 'amount', 'then', 'can', 'and', 'between', 'ourselves', 'was', 'bill', 'seem', 'you', 'being', 'him', 'of', 'rather', 'amoungst', 'everyone', 'before', 'elsewhere', 'under', 'your', 'towards'}), vect__tokenizer=&lt;function tokenizer at 0x10eaf3b00&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'much', 'its', 'itself', 'such', 'thin', 'seeming', 'more', 'themselves', 'still', 'which', 'well', 'whence', 'please', 'herein', 'ltd', 'less', 'why', 'indeed', 'several', 'whereas', 'had', 'already', 'wherein', 'noone', 'serious', 'besides', 'nine', 'must', 'anywhere', 'ten', 'three', 'hereafter', 'do', 'everything', 'co', 'anyhow', 'how', 'hereupon', 'throughout', 'off', 'thereafter', 'un', 'somewhere', 'could', 'any', 'you', 'ever', 'whenever', 'top', 'at', 'per', 'anything', 'however', 'against', 'from', 'eg', 'his', 'even', 'my', 'find', 'someone', 'but', 'both', 'twelve', 'have', 'sometime', 'should', 'who', 'up', 'six', 'con', 'last', 'when', 'though', 'everywhere', 'found', 'enough', 'cannot', 'few', 'whereby', 'behind', 'whither', 'due', 'seems', 'for', 'next', 'something', 'wherever', 'twenty', 'done', 'own', 'namely', 'keep', 'never', 'in', 'amount', 'without', 'inc', 'call', 'me', 'being', 'into', 'not', 'thereupon', 'bill', 'of', 'sixty', 'mill', 'nevertheless', 'before', 'every', 'nobody', 'etc', 'moreover', 'same', 'be', 'yet', 'because', 'nowhere', 'empty', 'latter', 'show', 'many', 'other', 'those', 'hence', 'across', 'most', 'herself', 'all', 'our', 'has', 'amoungst', 'see', 'either', 'whereupon', 'thence', 'another', 'name', 'take', 'detail', 'ourselves', 'whatever', 'became', 'whom', 'i', 'some', 'third', 'somehow', 'by', 'an', 'none', 'were', 'very', 'seem', 'she', 'describe', 'among', 'thick', 'them', 'first', 'these', 'anyone', 'us', 'side', 'thus', 'then', 'nor', 'ours', 'further', 'sincere', 'whoever', 'if', 'around', 'the', 'himself', 'after', 'together', 'so', 'alone', 'bottom', 'him', 'former', 'your', 'back', 'beside', 'over', 'out', 'except', 'couldnt', 'above', 'almost', 'two', 'hers', 'on', 'will', 'to', 'hereby', 'whether', 'until', 'front', 'perhaps', 'part', 'de', 'becoming', 'can', 'are', 'hundred', 'their', 'beyond', 'he', 'otherwise', 'thereby', 'or', 'down', 'as', 'else', 'full', 'upon', 'meanwhile', 'they', 'onto', 'mine', 'only', 'made', 'her', 'this', 'would', 'fire', 'eight', 'within', 'here', 'myself', 'go', 'between', 'may', 'thru', 'via', 'move', 'mostly', 'and', 'formerly', 'become', 'give', 'amongst', 'whereafter', 'sometimes', 'seemed', 'ie', 'others', 'yours', 'elsewhere', 'toward', 'during', 're', 'that', 'five', 'what', 'might', 'rather', 'about', 'yourselves', 'four', 'yourself', 'now', 'fill', 'again', 'since', 'while', 'there', 'fifty', 'although', 'get', 'always', 'than', 'a', 'afterwards', 'fifteen', 'with', 'least', 'am', 'therein', 'anyway', 'cant', 'hasnt', 'eleven', 'therefore', 'we', 'forty', 'is', 'nothing', 'everyone', 'latterly', 'where', 'often', 'system', 'becomes', 'along', 'one', 'cry', 'was', 'below', 'under', 'also', 'whose', 'been', 'each', 'towards', 'it', 'whole', 'beforehand', 'interest', 'through', 'once', 'neither', 'too', 'no', 'put'}), vect__tokenizer=&lt;function tokenizer at 0x10efafb00&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x112a2bb00&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'found', 'moreover', 'either', 'thereupon', 'otherwise', 'somehow', 'ours', 'if', 'but', 'anywhere', 'becoming', 'hasnt', 'you', 'his', 'ten', 'against', 'move', 'such', 'again', 'along', 'couldnt', 'hereupon', 'even', 'etc', 'nine', 'am', 'should', 'amoungst', 'give', 'into', 'made', 'onto', 'and', 'down', 'these', 'per', 'five', 'mostly', 'too', 'system', 'however', 'this', 'my', 'others', 'herein', 'elsewhere', 'much', 'whole', 'up', 'myself', 'whom', 'nobody', 'are', 'mill', 'interest', 'mine', 'indeed', 'why', 'formerly', 'almost', 'cannot', 'among', 'some', 'first', 'enough', 'thence', 'its', 'under', 'thick', 'latter', 'fifteen', 'not', 'everyone', 'though', 'by', 'beforehand', 'sometimes', 'former', 'yourselves', 'thereafter', 'beyond', 'anyway', 'something', 'an', 'except', 'themselves', 'eleven', 'hers', 'itself', 'been', 'can', 'herself', 'neither', 'ltd', 'upon', 'less', 'namely', 'each', 'thin', 'while', 'four', 'sincere', 'due', 'seems', 'here', 'perhaps', 'ie', 'he', 'none', 'most', 'to', 'both', 'top', 'in', 'could', 'own', 'third', 'amongst', 'through', 'hereby', 'off', 'toward', 'anyone', 'seem', 'take', 'yourself', 'throughout', 'further', 'meanwhile', 'our', 'therefore', 'via', 'there', 'she', 'go', 'it', 'become', 'seemed', 'so', 'several', 'will', 'sometime', 'bottom', 'someone', 'ourselves', 'fill', 'because', 'full', 'during', 'they', 'i', 'show', 'whenever', 'me', 're', 'would', 'often', 'whence', 'last', 'twelve', 'part', 'only', 'thru', 'once', 'anyhow', 'two', 'has', 'fire', 'other', 'as', 'find', 'himself', 'above', 'nevertheless', 'everything', 'them', 'six', 'we', 'be', 'somewhere', 'another', 'around', 'least', 'well', 'whose', 'whether', 'being', 'describe', 'eight', 'whereupon', 'than', 'please', 'noone', 'when', 'every', 'out', 'or', 'beside', 'seeming', 'inc', 'afterwards', 'might', 'whatever', 'always', 'from', 'although', 'their', 'twenty', 'more', 'below', 'hence', 'yet', 'before', 'the', 'whereas', 'do', 'behind', 'became', 'whither', 'front', 'that', 'yours', 'him', 'done', 'get', 'three', 'back', 'until', 'thus', 'empty', 'across', 'everywhere', 'forty', 'her', 'call', 'never', 'side', 'with', 'also', 'is', 'else', 'must', 'becomes', 'latterly', 'bill', 'few', 'those', 'same', 'co', 'de', 'cry', 'keep', 'at', 'after', 'sixty', 'whereafter', 'towards', 'between', 'your', 'cant', 'all', 'since', 'whereby', 'alone', 'many', 'what', 'nothing', 'for', 'hereafter', 'wherever', 'one', 'where', 'put', 'were', 'serious', 'fifty', 'without', 'eg', 'detail', 'which', 'of', 'any', 'un', 'rather', 'already', 'besides', 'next', 'nowhere', 'name', 'on', 'thereby', 'who', 'within', 'wherein', 'still', 'us', 'a', 'then', 'now', 'have', 'had', 'hundred', 'together', 'therein', 'anything', 'ever', 'amount', 'nor', 'may', 'very', 'see', 'over', 'was', 'how', 'con', 'no', 'about', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x11394c720&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'four', 'please', 'hundred', 'may', 'rather', 'get', 'thick', 'to', 'several', 'first', 'and', 'sixty', 'wherein', 'then', 'less', 'thereafter', 'one', 'well', 'formerly', 'hence', 'everything', 'of', 'every', 'co', 'although', 'whither', 'others', 'least', 'ever', 'with', 'whereby', 'seem', 'cry', 'her', 'his', 'ourselves', 'this', 'all', 'from', 'upon', 'even', 'often', 'among', 'therefore', 'amongst', 'three', 'most', 'done', 'nothing', 'been', 'other', 'eight', 'you', 'am', 'name', 'so', 'our', 'never', 'or', 'becomes', 'since', 'whereafter', 'herself', 'during', 'sincere', 'over', 'more', 'anyone', 'if', 'will', 'hereby', 'thin', 'interest', 'whence', 'thru', 'ten', 'nowhere', 'in', 'the', 'last', 'twelve', 'thereby', 'were', 'towards', 'these', 'whoever', 'mine', 'along', 'itself', 'within', 'that', 'now', 'un', 'themselves', 'former', 'afterwards', 'have', 'is', 'ltd', 'fifteen', 'before', 'yourselves', 'show', 'somewhere', 'up', 'yourself', 'latterly', 'across', 'why', 'eleven', 'on', 'about', 'himself', 'detail', 'amount', 'though', 'who', 'your', 'latter', 'hasnt', 'off', 'mostly', 'serious', 'can', 'down', 'beyond', 'both', 'give', 'behind', 'many', 'here', 'per', 'had', 'anyway', 'found', 'could', 'are', 'move', 'ie', 'became', 'indeed', 'same', 'elsewhere', 'keep', 'must', 'might', 'six', 'no', 'him', 'between', 'moreover', 'whatever', 'still', 'whole', 'hereupon', 'someone', 'them', 'anyhow', 'after', 'thereupon', 'wherever', 'twenty', 'would', 'there', 'else', 'whereupon', 'beside', 'fill', 'sometime', 'once', 'yours', 'inc', 'which', 'not', 'seems', 'was', 'meanwhile', 'system', 'only', 'couldnt', 'thus', 'thence', 'hereafter', 'further', 'amoungst', 'few', 'together', 'everywhere', 'because', 'nine', 'eg', 'nor', 'yet', 'bottom', 'how', 'back', 'but', 'neither', 'bill', 'he', 'it', 'already', 'through', 'five', 'via', 'find', 'under', 'de', 'whose', 'be', 'ours', 'below', 'until', 'perhaps', 'me', 'those', 'con', 'forty', 'nevertheless', 'everyone', 'its', 'describe', 'become', 'always', 'part', 'very', 'somehow', 'none', 'see', 'at', 'otherwise', 'as', 'therein', 'something', 'full', 'third', 'empty', 'into', 'fifty', 'call', 'should', 'onto', 'cant', 'front', 'noone', 'we', 'where', 'myself', 'against', 'made', 'namely', 'has', 'anywhere', 'their', 'top', 'herein', 'for', 'whereas', 'hers', 'nobody', 'mill', 'cannot', 'another', 'when', 'throughout', 'fire', 'without', 'toward', 'such', 'own', 'sometimes', 'some', 'she', 'seeming', 'besides', 'than', 'around', 'an', 'they', 'my', 'alone', 'either', 'each', 'except', 'whether', 'next', 'put', 'however', 'i', 'two', 'us', 'above', 'whom', 'beforehand', 'by', 'much', 'also', 'too', 'whenever', 'enough', 'anything', 'a', 'seemed', 'becoming', 'almost', 'out', 'etc', 'being', 'go', 'due', 'again', 'while', 'what', 'take', 'any', 're', 'do', 'side'}), vect__tokenizer=&lt;function tokenizer_porter at 0x112e70720&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x112b7b9c0&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer_porter at 0x111354720&gt;; total time=   0.0s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'nothing', 'describe', 'latter', 'beyond', 'please', 'however', 'will', 'a', 'all', 'whoever', 'least', 'therein', 'along', 'thereby', 'further', 'get', 'whereafter', 'herein', 'yours', 'eleven', 'some', 'else', 'through', 'hasnt', 'within', 'whither', 'eight', 'would', 'fill', 'last', 'anywhere', 'go', 'very', 'much', 'before', 'still', 'seeming', 'next', 'where', 'other', 'we', 'whereas', 'has', 'anyone', 'sixty', 'must', 'who', 'about', 'at', 'enough', 'nobody', 'itself', 'ours', 'them', 'whereby', 'serious', 'whose', 'such', 'full', 'keep', 'myself', 'even', 'thin', 'via', 'ourselves', 'but', 'anyway', 'too', 'cannot', 'twelve', 'which', 'yourselves', 'your', 'something', 'everywhere', 'their', 'above', 'less', 'might', 'alone', 'two', 'can', 'side', 'be', 'nor', 'former', 'of', 'several', 'forty', 'than', 'ten', 'her', 'me', 'whenever', 'was', 'con', 'done', 'while', 'himself', 'find', 'formerly', 'namely', 'onto', 'whether', 'etc', 'to', 'sometimes', 'yet', 'everything', 'among', 'may', 'someone', 'across', 'whatever', 'and', 'nine', 'perhaps', 'since', 'against', 'thru', 'three', 'with', 'indeed', 'on', 'de', 'these', 'when', 'though', 'seems', 'sometime', 'him', 'only', 'rather', 'those', 'had', 'noone', 'there', 'could', 'sincere', 'thus', 'mine', 'many', 'detail', 'am', 'moreover', 'until', 'top', 'give', 'up', 'somehow', 'anything', 'yourself', 'is', 'either', 'somewhere', 'hence', 'here', 'it', 'front', 'no', 'couldnt', 'the', 'from', 'off', 'co', 'because', 'that', 'made', 'why', 'this', 'amongst', 'after', 'twenty', 'none', 'each', 'by', 'becoming', 'more', 'amoungst', 'eg', 'thereafter', 'due', 'take', 'move', 'do', 'five', 'never', 'elsewhere', 'anyhow', 'ie', 'without', 'part', 'call', 'interest', 'see', 'often', 'how', 'per', 'for', 'hereby', 'what', 'neither', 'thick', 'hundred', 'became', 'whom', 'throughout', 'towards', 'thence', 'put', 'besides', 'third', 'being', 'almost', 'over', 'bottom', 'meanwhile', 'not', 'us', 'nowhere', 'seemed', 'i', 'mill', 'otherwise', 'every', 'into', 'four', 'if', 'first', 'behind', 'fifty', 'once', 'wherein', 'own', 'others', 'beside', 'fifteen', 'thereupon', 'hers', 'one', 'now', 'hereupon', 'show', 'around', 'although', 'another', 'whence', 'hereafter', 'are', 'name', 'back', 'become', 'well', 'cry', 'except', 'seem', 're', 'already', 'ever', 'whereupon', 'wherever', 'down', 'always', 'toward', 'same', 'been', 'together', 'again', 'afterwards', 'under', 'between', 'un', 'therefore', 'six', 'inc', 'then', 'herself', 'bill', 'out', 'his', 'you', 'cant', 'its', 'he', 'both', 'during', 'everyone', 'most', 'system', 'they', 'have', 'upon', 'so', 'in', 'ltd', 'beforehand', 'empty', 'or', 'my', 'themselves', 'few', 'mostly', 'were', 'latterly', 'whole', 'our', 'found', 'should', 'fire', 'she', 'also', 'becomes', 'any', 'an', 'as', 'nevertheless', 'amount', 'below'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10f238720&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'found', 'moreover', 'either', 'thereupon', 'otherwise', 'somehow', 'ours', 'if', 'but', 'anywhere', 'becoming', 'hasnt', 'you', 'his', 'ten', 'against', 'move', 'such', 'again', 'along', 'couldnt', 'hereupon', 'even', 'etc', 'nine', 'am', 'should', 'amoungst', 'give', 'into', 'made', 'onto', 'and', 'down', 'these', 'per', 'five', 'mostly', 'too', 'system', 'however', 'this', 'my', 'others', 'herein', 'elsewhere', 'much', 'whole', 'up', 'myself', 'whom', 'nobody', 'are', 'mill', 'interest', 'mine', 'indeed', 'why', 'formerly', 'almost', 'cannot', 'among', 'some', 'first', 'enough', 'thence', 'its', 'under', 'thick', 'latter', 'fifteen', 'not', 'everyone', 'though', 'by', 'beforehand', 'sometimes', 'former', 'yourselves', 'thereafter', 'beyond', 'anyway', 'something', 'an', 'except', 'themselves', 'eleven', 'hers', 'itself', 'been', 'can', 'herself', 'neither', 'ltd', 'upon', 'less', 'namely', 'each', 'thin', 'while', 'four', 'sincere', 'due', 'seems', 'here', 'perhaps', 'ie', 'he', 'none', 'most', 'to', 'both', 'top', 'in', 'could', 'own', 'third', 'amongst', 'through', 'hereby', 'off', 'toward', 'anyone', 'seem', 'take', 'yourself', 'throughout', 'further', 'meanwhile', 'our', 'therefore', 'via', 'there', 'she', 'go', 'it', 'become', 'seemed', 'so', 'several', 'will', 'sometime', 'bottom', 'someone', 'ourselves', 'fill', 'because', 'full', 'during', 'they', 'i', 'show', 'whenever', 'me', 're', 'would', 'often', 'whence', 'last', 'twelve', 'part', 'only', 'thru', 'once', 'anyhow', 'two', 'has', 'fire', 'other', 'as', 'find', 'himself', 'above', 'nevertheless', 'everything', 'them', 'six', 'we', 'be', 'somewhere', 'another', 'around', 'least', 'well', 'whose', 'whether', 'being', 'describe', 'eight', 'whereupon', 'than', 'please', 'noone', 'when', 'every', 'out', 'or', 'beside', 'seeming', 'inc', 'afterwards', 'might', 'whatever', 'always', 'from', 'although', 'their', 'twenty', 'more', 'below', 'hence', 'yet', 'before', 'the', 'whereas', 'do', 'behind', 'became', 'whither', 'front', 'that', 'yours', 'him', 'done', 'get', 'three', 'back', 'until', 'thus', 'empty', 'across', 'everywhere', 'forty', 'her', 'call', 'never', 'side', 'with', 'also', 'is', 'else', 'must', 'becomes', 'latterly', 'bill', 'few', 'those', 'same', 'co', 'de', 'cry', 'keep', 'at', 'after', 'sixty', 'whereafter', 'towards', 'between', 'your', 'cant', 'all', 'since', 'whereby', 'alone', 'many', 'what', 'nothing', 'for', 'hereafter', 'wherever', 'one', 'where', 'put', 'were', 'serious', 'fifty', 'without', 'eg', 'detail', 'which', 'of', 'any', 'un', 'rather', 'already', 'besides', 'next', 'nowhere', 'name', 'on', 'thereby', 'who', 'within', 'wherein', 'still', 'us', 'a', 'then', 'now', 'have', 'had', 'hundred', 'together', 'therein', 'anything', 'ever', 'amount', 'nor', 'may', 'very', 'see', 'over', 'was', 'how', 'con', 'no', 'about', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x10b18e3e0&gt;; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10fc1c720&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer at 0x108baa3e0&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'found', 'moreover', 'either', 'thereupon', 'otherwise', 'somehow', 'ours', 'if', 'but', 'anywhere', 'becoming', 'hasnt', 'you', 'his', 'ten', 'against', 'move', 'such', 'again', 'along', 'couldnt', 'hereupon', 'even', 'etc', 'nine', 'am', 'should', 'amoungst', 'give', 'into', 'made', 'onto', 'and', 'down', 'these', 'per', 'five', 'mostly', 'too', 'system', 'however', 'this', 'my', 'others', 'herein', 'elsewhere', 'much', 'whole', 'up', 'myself', 'whom', 'nobody', 'are', 'mill', 'interest', 'mine', 'indeed', 'why', 'formerly', 'almost', 'cannot', 'among', 'some', 'first', 'enough', 'thence', 'its', 'under', 'thick', 'latter', 'fifteen', 'not', 'everyone', 'though', 'by', 'beforehand', 'sometimes', 'former', 'yourselves', 'thereafter', 'beyond', 'anyway', 'something', 'an', 'except', 'themselves', 'eleven', 'hers', 'itself', 'been', 'can', 'herself', 'neither', 'ltd', 'upon', 'less', 'namely', 'each', 'thin', 'while', 'four', 'sincere', 'due', 'seems', 'here', 'perhaps', 'ie', 'he', 'none', 'most', 'to', 'both', 'top', 'in', 'could', 'own', 'third', 'amongst', 'through', 'hereby', 'off', 'toward', 'anyone', 'seem', 'take', 'yourself', 'throughout', 'further', 'meanwhile', 'our', 'therefore', 'via', 'there', 'she', 'go', 'it', 'become', 'seemed', 'so', 'several', 'will', 'sometime', 'bottom', 'someone', 'ourselves', 'fill', 'because', 'full', 'during', 'they', 'i', 'show', 'whenever', 'me', 're', 'would', 'often', 'whence', 'last', 'twelve', 'part', 'only', 'thru', 'once', 'anyhow', 'two', 'has', 'fire', 'other', 'as', 'find', 'himself', 'above', 'nevertheless', 'everything', 'them', 'six', 'we', 'be', 'somewhere', 'another', 'around', 'least', 'well', 'whose', 'whether', 'being', 'describe', 'eight', 'whereupon', 'than', 'please', 'noone', 'when', 'every', 'out', 'or', 'beside', 'seeming', 'inc', 'afterwards', 'might', 'whatever', 'always', 'from', 'although', 'their', 'twenty', 'more', 'below', 'hence', 'yet', 'before', 'the', 'whereas', 'do', 'behind', 'became', 'whither', 'front', 'that', 'yours', 'him', 'done', 'get', 'three', 'back', 'until', 'thus', 'empty', 'across', 'everywhere', 'forty', 'her', 'call', 'never', 'side', 'with', 'also', 'is', 'else', 'must', 'becomes', 'latterly', 'bill', 'few', 'those', 'same', 'co', 'de', 'cry', 'keep', 'at', 'after', 'sixty', 'whereafter', 'towards', 'between', 'your', 'cant', 'all', 'since', 'whereby', 'alone', 'many', 'what', 'nothing', 'for', 'hereafter', 'wherever', 'one', 'where', 'put', 'were', 'serious', 'fifty', 'without', 'eg', 'detail', 'which', 'of', 'any', 'un', 'rather', 'already', 'besides', 'next', 'nowhere', 'name', 'on', 'thereby', 'who', 'within', 'wherein', 'still', 'us', 'a', 'then', 'now', 'have', 'had', 'hundred', 'together', 'therein', 'anything', 'ever', 'amount', 'nor', 'may', 'very', 'see', 'over', 'was', 'how', 'con', 'no', 'about', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x1133c7740&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'four', 'please', 'hundred', 'may', 'rather', 'get', 'thick', 'to', 'several', 'first', 'and', 'sixty', 'wherein', 'then', 'less', 'thereafter', 'one', 'well', 'formerly', 'hence', 'everything', 'of', 'every', 'co', 'although', 'whither', 'others', 'least', 'ever', 'with', 'whereby', 'seem', 'cry', 'her', 'his', 'ourselves', 'this', 'all', 'from', 'upon', 'even', 'often', 'among', 'therefore', 'amongst', 'three', 'most', 'done', 'nothing', 'been', 'other', 'eight', 'you', 'am', 'name', 'so', 'our', 'never', 'or', 'becomes', 'since', 'whereafter', 'herself', 'during', 'sincere', 'over', 'more', 'anyone', 'if', 'will', 'hereby', 'thin', 'interest', 'whence', 'thru', 'ten', 'nowhere', 'in', 'the', 'last', 'twelve', 'thereby', 'were', 'towards', 'these', 'whoever', 'mine', 'along', 'itself', 'within', 'that', 'now', 'un', 'themselves', 'former', 'afterwards', 'have', 'is', 'ltd', 'fifteen', 'before', 'yourselves', 'show', 'somewhere', 'up', 'yourself', 'latterly', 'across', 'why', 'eleven', 'on', 'about', 'himself', 'detail', 'amount', 'though', 'who', 'your', 'latter', 'hasnt', 'off', 'mostly', 'serious', 'can', 'down', 'beyond', 'both', 'give', 'behind', 'many', 'here', 'per', 'had', 'anyway', 'found', 'could', 'are', 'move', 'ie', 'became', 'indeed', 'same', 'elsewhere', 'keep', 'must', 'might', 'six', 'no', 'him', 'between', 'moreover', 'whatever', 'still', 'whole', 'hereupon', 'someone', 'them', 'anyhow', 'after', 'thereupon', 'wherever', 'twenty', 'would', 'there', 'else', 'whereupon', 'beside', 'fill', 'sometime', 'once', 'yours', 'inc', 'which', 'not', 'seems', 'was', 'meanwhile', 'system', 'only', 'couldnt', 'thus', 'thence', 'hereafter', 'further', 'amoungst', 'few', 'together', 'everywhere', 'because', 'nine', 'eg', 'nor', 'yet', 'bottom', 'how', 'back', 'but', 'neither', 'bill', 'he', 'it', 'already', 'through', 'five', 'via', 'find', 'under', 'de', 'whose', 'be', 'ours', 'below', 'until', 'perhaps', 'me', 'those', 'con', 'forty', 'nevertheless', 'everyone', 'its', 'describe', 'become', 'always', 'part', 'very', 'somehow', 'none', 'see', 'at', 'otherwise', 'as', 'therein', 'something', 'full', 'third', 'empty', 'into', 'fifty', 'call', 'should', 'onto', 'cant', 'front', 'noone', 'we', 'where', 'myself', 'against', 'made', 'namely', 'has', 'anywhere', 'their', 'top', 'herein', 'for', 'whereas', 'hers', 'nobody', 'mill', 'cannot', 'another', 'when', 'throughout', 'fire', 'without', 'toward', 'such', 'own', 'sometimes', 'some', 'she', 'seeming', 'besides', 'than', 'around', 'an', 'they', 'my', 'alone', 'either', 'each', 'except', 'whether', 'next', 'put', 'however', 'i', 'two', 'us', 'above', 'whom', 'beforehand', 'by', 'much', 'also', 'too', 'whenever', 'enough', 'anything', 'a', 'seemed', 'becoming', 'almost', 'out', 'etc', 'being', 'go', 'due', 'again', 'while', 'what', 'take', 'any', 're', 'do', 'side'}), vect__tokenizer=&lt;function tokenizer at 0x10a72a3e0&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'found', 'moreover', 'either', 'thereupon', 'otherwise', 'somehow', 'ours', 'if', 'but', 'anywhere', 'becoming', 'hasnt', 'you', 'his', 'ten', 'against', 'move', 'such', 'again', 'along', 'couldnt', 'hereupon', 'even', 'etc', 'nine', 'am', 'should', 'amoungst', 'give', 'into', 'made', 'onto', 'and', 'down', 'these', 'per', 'five', 'mostly', 'too', 'system', 'however', 'this', 'my', 'others', 'herein', 'elsewhere', 'much', 'whole', 'up', 'myself', 'whom', 'nobody', 'are', 'mill', 'interest', 'mine', 'indeed', 'why', 'formerly', 'almost', 'cannot', 'among', 'some', 'first', 'enough', 'thence', 'its', 'under', 'thick', 'latter', 'fifteen', 'not', 'everyone', 'though', 'by', 'beforehand', 'sometimes', 'former', 'yourselves', 'thereafter', 'beyond', 'anyway', 'something', 'an', 'except', 'themselves', 'eleven', 'hers', 'itself', 'been', 'can', 'herself', 'neither', 'ltd', 'upon', 'less', 'namely', 'each', 'thin', 'while', 'four', 'sincere', 'due', 'seems', 'here', 'perhaps', 'ie', 'he', 'none', 'most', 'to', 'both', 'top', 'in', 'could', 'own', 'third', 'amongst', 'through', 'hereby', 'off', 'toward', 'anyone', 'seem', 'take', 'yourself', 'throughout', 'further', 'meanwhile', 'our', 'therefore', 'via', 'there', 'she', 'go', 'it', 'become', 'seemed', 'so', 'several', 'will', 'sometime', 'bottom', 'someone', 'ourselves', 'fill', 'because', 'full', 'during', 'they', 'i', 'show', 'whenever', 'me', 're', 'would', 'often', 'whence', 'last', 'twelve', 'part', 'only', 'thru', 'once', 'anyhow', 'two', 'has', 'fire', 'other', 'as', 'find', 'himself', 'above', 'nevertheless', 'everything', 'them', 'six', 'we', 'be', 'somewhere', 'another', 'around', 'least', 'well', 'whose', 'whether', 'being', 'describe', 'eight', 'whereupon', 'than', 'please', 'noone', 'when', 'every', 'out', 'or', 'beside', 'seeming', 'inc', 'afterwards', 'might', 'whatever', 'always', 'from', 'although', 'their', 'twenty', 'more', 'below', 'hence', 'yet', 'before', 'the', 'whereas', 'do', 'behind', 'became', 'whither', 'front', 'that', 'yours', 'him', 'done', 'get', 'three', 'back', 'until', 'thus', 'empty', 'across', 'everywhere', 'forty', 'her', 'call', 'never', 'side', 'with', 'also', 'is', 'else', 'must', 'becomes', 'latterly', 'bill', 'few', 'those', 'same', 'co', 'de', 'cry', 'keep', 'at', 'after', 'sixty', 'whereafter', 'towards', 'between', 'your', 'cant', 'all', 'since', 'whereby', 'alone', 'many', 'what', 'nothing', 'for', 'hereafter', 'wherever', 'one', 'where', 'put', 'were', 'serious', 'fifty', 'without', 'eg', 'detail', 'which', 'of', 'any', 'un', 'rather', 'already', 'besides', 'next', 'nowhere', 'name', 'on', 'thereby', 'who', 'within', 'wherein', 'still', 'us', 'a', 'then', 'now', 'have', 'had', 'hundred', 'together', 'therein', 'anything', 'ever', 'amount', 'nor', 'may', 'very', 'see', 'over', 'was', 'how', 'con', 'no', 'about', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x1139013a0&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'four', 'please', 'hundred', 'may', 'rather', 'get', 'thick', 'to', 'several', 'first', 'and', 'sixty', 'wherein', 'then', 'less', 'thereafter', 'one', 'well', 'formerly', 'hence', 'everything', 'of', 'every', 'co', 'although', 'whither', 'others', 'least', 'ever', 'with', 'whereby', 'seem', 'cry', 'her', 'his', 'ourselves', 'this', 'all', 'from', 'upon', 'even', 'often', 'among', 'therefore', 'amongst', 'three', 'most', 'done', 'nothing', 'been', 'other', 'eight', 'you', 'am', 'name', 'so', 'our', 'never', 'or', 'becomes', 'since', 'whereafter', 'herself', 'during', 'sincere', 'over', 'more', 'anyone', 'if', 'will', 'hereby', 'thin', 'interest', 'whence', 'thru', 'ten', 'nowhere', 'in', 'the', 'last', 'twelve', 'thereby', 'were', 'towards', 'these', 'whoever', 'mine', 'along', 'itself', 'within', 'that', 'now', 'un', 'themselves', 'former', 'afterwards', 'have', 'is', 'ltd', 'fifteen', 'before', 'yourselves', 'show', 'somewhere', 'up', 'yourself', 'latterly', 'across', 'why', 'eleven', 'on', 'about', 'himself', 'detail', 'amount', 'though', 'who', 'your', 'latter', 'hasnt', 'off', 'mostly', 'serious', 'can', 'down', 'beyond', 'both', 'give', 'behind', 'many', 'here', 'per', 'had', 'anyway', 'found', 'could', 'are', 'move', 'ie', 'became', 'indeed', 'same', 'elsewhere', 'keep', 'must', 'might', 'six', 'no', 'him', 'between', 'moreover', 'whatever', 'still', 'whole', 'hereupon', 'someone', 'them', 'anyhow', 'after', 'thereupon', 'wherever', 'twenty', 'would', 'there', 'else', 'whereupon', 'beside', 'fill', 'sometime', 'once', 'yours', 'inc', 'which', 'not', 'seems', 'was', 'meanwhile', 'system', 'only', 'couldnt', 'thus', 'thence', 'hereafter', 'further', 'amoungst', 'few', 'together', 'everywhere', 'because', 'nine', 'eg', 'nor', 'yet', 'bottom', 'how', 'back', 'but', 'neither', 'bill', 'he', 'it', 'already', 'through', 'five', 'via', 'find', 'under', 'de', 'whose', 'be', 'ours', 'below', 'until', 'perhaps', 'me', 'those', 'con', 'forty', 'nevertheless', 'everyone', 'its', 'describe', 'become', 'always', 'part', 'very', 'somehow', 'none', 'see', 'at', 'otherwise', 'as', 'therein', 'something', 'full', 'third', 'empty', 'into', 'fifty', 'call', 'should', 'onto', 'cant', 'front', 'noone', 'we', 'where', 'myself', 'against', 'made', 'namely', 'has', 'anywhere', 'their', 'top', 'herein', 'for', 'whereas', 'hers', 'nobody', 'mill', 'cannot', 'another', 'when', 'throughout', 'fire', 'without', 'toward', 'such', 'own', 'sometimes', 'some', 'she', 'seeming', 'besides', 'than', 'around', 'an', 'they', 'my', 'alone', 'either', 'each', 'except', 'whether', 'next', 'put', 'however', 'i', 'two', 'us', 'above', 'whom', 'beforehand', 'by', 'much', 'also', 'too', 'whenever', 'enough', 'anything', 'a', 'seemed', 'becoming', 'almost', 'out', 'etc', 'being', 'go', 'due', 'again', 'while', 'what', 'take', 'any', 're', 'do', 'side'}), vect__tokenizer=&lt;function tokenizer_porter at 0x112e253a0&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x113024720&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'found', 'moreover', 'either', 'thereupon', 'otherwise', 'somehow', 'ours', 'if', 'but', 'anywhere', 'becoming', 'hasnt', 'you', 'his', 'ten', 'against', 'move', 'such', 'again', 'along', 'couldnt', 'hereupon', 'even', 'etc', 'nine', 'am', 'should', 'amoungst', 'give', 'into', 'made', 'onto', 'and', 'down', 'these', 'per', 'five', 'mostly', 'too', 'system', 'however', 'this', 'my', 'others', 'herein', 'elsewhere', 'much', 'whole', 'up', 'myself', 'whom', 'nobody', 'are', 'mill', 'interest', 'mine', 'indeed', 'why', 'formerly', 'almost', 'cannot', 'among', 'some', 'first', 'enough', 'thence', 'its', 'under', 'thick', 'latter', 'fifteen', 'not', 'everyone', 'though', 'by', 'beforehand', 'sometimes', 'former', 'yourselves', 'thereafter', 'beyond', 'anyway', 'something', 'an', 'except', 'themselves', 'eleven', 'hers', 'itself', 'been', 'can', 'herself', 'neither', 'ltd', 'upon', 'less', 'namely', 'each', 'thin', 'while', 'four', 'sincere', 'due', 'seems', 'here', 'perhaps', 'ie', 'he', 'none', 'most', 'to', 'both', 'top', 'in', 'could', 'own', 'third', 'amongst', 'through', 'hereby', 'off', 'toward', 'anyone', 'seem', 'take', 'yourself', 'throughout', 'further', 'meanwhile', 'our', 'therefore', 'via', 'there', 'she', 'go', 'it', 'become', 'seemed', 'so', 'several', 'will', 'sometime', 'bottom', 'someone', 'ourselves', 'fill', 'because', 'full', 'during', 'they', 'i', 'show', 'whenever', 'me', 're', 'would', 'often', 'whence', 'last', 'twelve', 'part', 'only', 'thru', 'once', 'anyhow', 'two', 'has', 'fire', 'other', 'as', 'find', 'himself', 'above', 'nevertheless', 'everything', 'them', 'six', 'we', 'be', 'somewhere', 'another', 'around', 'least', 'well', 'whose', 'whether', 'being', 'describe', 'eight', 'whereupon', 'than', 'please', 'noone', 'when', 'every', 'out', 'or', 'beside', 'seeming', 'inc', 'afterwards', 'might', 'whatever', 'always', 'from', 'although', 'their', 'twenty', 'more', 'below', 'hence', 'yet', 'before', 'the', 'whereas', 'do', 'behind', 'became', 'whither', 'front', 'that', 'yours', 'him', 'done', 'get', 'three', 'back', 'until', 'thus', 'empty', 'across', 'everywhere', 'forty', 'her', 'call', 'never', 'side', 'with', 'also', 'is', 'else', 'must', 'becomes', 'latterly', 'bill', 'few', 'those', 'same', 'co', 'de', 'cry', 'keep', 'at', 'after', 'sixty', 'whereafter', 'towards', 'between', 'your', 'cant', 'all', 'since', 'whereby', 'alone', 'many', 'what', 'nothing', 'for', 'hereafter', 'wherever', 'one', 'where', 'put', 'were', 'serious', 'fifty', 'without', 'eg', 'detail', 'which', 'of', 'any', 'un', 'rather', 'already', 'besides', 'next', 'nowhere', 'name', 'on', 'thereby', 'who', 'within', 'wherein', 'still', 'us', 'a', 'then', 'now', 'have', 'had', 'hundred', 'together', 'therein', 'anything', 'ever', 'amount', 'nor', 'may', 'very', 'see', 'over', 'was', 'how', 'con', 'no', 'about', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x11471fe20&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'nothing', 'describe', 'latter', 'beyond', 'please', 'however', 'will', 'a', 'all', 'whoever', 'least', 'therein', 'along', 'thereby', 'further', 'get', 'whereafter', 'herein', 'yours', 'eleven', 'some', 'else', 'through', 'hasnt', 'within', 'whither', 'eight', 'would', 'fill', 'last', 'anywhere', 'go', 'very', 'much', 'before', 'still', 'seeming', 'next', 'where', 'other', 'we', 'whereas', 'has', 'anyone', 'sixty', 'must', 'who', 'about', 'at', 'enough', 'nobody', 'itself', 'ours', 'them', 'whereby', 'serious', 'whose', 'such', 'full', 'keep', 'myself', 'even', 'thin', 'via', 'ourselves', 'but', 'anyway', 'too', 'cannot', 'twelve', 'which', 'yourselves', 'your', 'something', 'everywhere', 'their', 'above', 'less', 'might', 'alone', 'two', 'can', 'side', 'be', 'nor', 'former', 'of', 'several', 'forty', 'than', 'ten', 'her', 'me', 'whenever', 'was', 'con', 'done', 'while', 'himself', 'find', 'formerly', 'namely', 'onto', 'whether', 'etc', 'to', 'sometimes', 'yet', 'everything', 'among', 'may', 'someone', 'across', 'whatever', 'and', 'nine', 'perhaps', 'since', 'against', 'thru', 'three', 'with', 'indeed', 'on', 'de', 'these', 'when', 'though', 'seems', 'sometime', 'him', 'only', 'rather', 'those', 'had', 'noone', 'there', 'could', 'sincere', 'thus', 'mine', 'many', 'detail', 'am', 'moreover', 'until', 'top', 'give', 'up', 'somehow', 'anything', 'yourself', 'is', 'either', 'somewhere', 'hence', 'here', 'it', 'front', 'no', 'couldnt', 'the', 'from', 'off', 'co', 'because', 'that', 'made', 'why', 'this', 'amongst', 'after', 'twenty', 'none', 'each', 'by', 'becoming', 'more', 'amoungst', 'eg', 'thereafter', 'due', 'take', 'move', 'do', 'five', 'never', 'elsewhere', 'anyhow', 'ie', 'without', 'part', 'call', 'interest', 'see', 'often', 'how', 'per', 'for', 'hereby', 'what', 'neither', 'thick', 'hundred', 'became', 'whom', 'throughout', 'towards', 'thence', 'put', 'besides', 'third', 'being', 'almost', 'over', 'bottom', 'meanwhile', 'not', 'us', 'nowhere', 'seemed', 'i', 'mill', 'otherwise', 'every', 'into', 'four', 'if', 'first', 'behind', 'fifty', 'once', 'wherein', 'own', 'others', 'beside', 'fifteen', 'thereupon', 'hers', 'one', 'now', 'hereupon', 'show', 'around', 'although', 'another', 'whence', 'hereafter', 'are', 'name', 'back', 'become', 'well', 'cry', 'except', 'seem', 're', 'already', 'ever', 'whereupon', 'wherever', 'down', 'always', 'toward', 'same', 'been', 'together', 'again', 'afterwards', 'under', 'between', 'un', 'therefore', 'six', 'inc', 'then', 'herself', 'bill', 'out', 'his', 'you', 'cant', 'its', 'he', 'both', 'during', 'everyone', 'most', 'system', 'they', 'have', 'upon', 'so', 'in', 'ltd', 'beforehand', 'empty', 'or', 'my', 'themselves', 'few', 'mostly', 'were', 'latterly', 'whole', 'our', 'found', 'should', 'fire', 'she', 'also', 'becomes', 'any', 'an', 'as', 'nevertheless', 'amount', 'below'}), vect__tokenizer=&lt;function tokenizer_porter at 0x106aedd00&gt;; total time=   0.0s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x1129b7c40&gt;; total time=   2.5s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x110a0bc40&gt;; total time=   2.5s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x11085bb00&gt;; total time=   2.6s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10ebbbb00&gt;; total time=   2.6s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10f117c40&gt;; total time=   2.6s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}), vect__tokenizer=&lt;function tokenizer at 0x10f263b00&gt;; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}), vect__tokenizer=&lt;function tokenizer at 0x106fc1d00&gt;; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}), vect__tokenizer=&lt;function tokenizer at 0x106fc63e0&gt;; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}), vect__tokenizer=&lt;function tokenizer at 0x10f117c40&gt;; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}), vect__tokenizer=&lt;function tokenizer at 0x10f263b00&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x110d6b740&gt;; total time=   2.8s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer_porter at 0x1113093a0&gt;; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10f711260&gt;; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer_porter at 0x112123e20&gt;; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}), vect__tokenizer=&lt;function tokenizer_porter at 0x11061b100&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10b18e3e0&gt;; total time=   2.8s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer_porter at 0x110d37b00&gt;; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10ecaf740&gt;; total time=   2.9s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x112ae4540&gt;; total time=   2.9s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x113c07e20&gt;; total time=   3.0s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x110d6b740&gt;; total time=   2.9s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10f6c54e0&gt;; total time=   3.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10ffefe20&gt;; total time=   3.1s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x1133c7740&gt;; total time=   3.1s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10a91dd00&gt;; total time=   3.1s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x10a9223e0&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x112b7b9c0&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x112ae4540&gt;, vect__use_idf=False; total time=   0.0s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x10a91dd00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer at 0x10a9223e0&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x113ea6e80&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x112b7b9c0&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x112ae4540&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10a91dd00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10a9223e0&gt;, vect__use_idf=False; total time=   0.0s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x112acbc40&gt;, vect__use_idf=False; total time=   4.3s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x113ea6e80&gt;, vect__use_idf=False; total time=   4.5s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x112b7b9c0&gt;, vect__use_idf=False; total time=   4.6s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10a9223e0&gt;, vect__use_idf=False; total time=   4.5s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f1149a0&gt;; total time=  27.2s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f5d09a0&gt;; total time=  27.5s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x110e28860&gt;; total time=  27.4s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f6009a0&gt;; total time=  27.6s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10fab09a0&gt;; total time=  27.8s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x107469d00&gt;; total time=  28.1s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer at 0x10f633740&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer at 0x1109abe20&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer at 0x10f5fbb00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer at 0x107469d00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer at 0x10f633740&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10fbd53a0&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer_porter at 0x1109abe20&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10f5fbb00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer_porter at 0x107469d00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'anywhere', 'detail', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10f633740&gt;, vect__use_idf=False; total time=   0.0s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x112ae4540&gt;, vect__use_idf=False; total time=   4.5s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x111028ae0&gt;; total time=  27.8s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x112fb0ae0&gt;; total time=  27.9s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f1a89a0&gt;; total time=  28.1s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x110e789a0&gt;; total time=  28.5s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x112e70720&gt;; total time=  29.3s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x11394c9a0&gt;; total time=  28.3s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x1109abe20&gt;, vect__use_idf=False; total time=   5.8s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f1d0680&gt;; total time=  28.6s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x1113549a0&gt;; total time=  29.2s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer at 0x110dd7c40&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f239080&gt;; total time=  29.1s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer at 0x110d37b00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'nothing', 'describe', 'latter', 'beyond', 'please', 'however', 'will', 'a', 'all', 'whoever', 'least', 'therein', 'along', 'thereby', 'further', 'get', 'whereafter', 'herein', 'yours', 'eleven', 'some', 'else', 'through', 'hasnt', 'within', 'whither', 'eight', 'would', 'fill', 'last', 'anywhere', 'go', 'very', 'much', 'before', 'still', 'seeming', 'next', 'where', 'other', 'we', 'whereas', 'has', 'anyone', 'sixty', 'must', 'who', 'about', 'at', 'enough', 'nobody', 'itself', 'ours', 'them', 'whereby', 'serious', 'whose', 'such', 'full', 'keep', 'myself', 'even', 'thin', 'via', 'ourselves', 'but', 'anyway', 'too', 'cannot', 'twelve', 'which', 'yourselves', 'your', 'something', 'everywhere', 'their', 'above', 'less', 'might', 'alone', 'two', 'can', 'side', 'be', 'nor', 'former', 'of', 'several', 'forty', 'than', 'ten', 'her', 'me', 'whenever', 'was', 'con', 'done', 'while', 'himself', 'find', 'formerly', 'namely', 'onto', 'whether', 'etc', 'to', 'sometimes', 'yet', 'everything', 'among', 'may', 'someone', 'across', 'whatever', 'and', 'nine', 'perhaps', 'since', 'against', 'thru', 'three', 'with', 'indeed', 'on', 'de', 'these', 'when', 'though', 'seems', 'sometime', 'him', 'only', 'rather', 'those', 'had', 'noone', 'there', 'could', 'sincere', 'thus', 'mine', 'many', 'detail', 'am', 'moreover', 'until', 'top', 'give', 'up', 'somehow', 'anything', 'yourself', 'is', 'either', 'somewhere', 'hence', 'here', 'it', 'front', 'no', 'couldnt', 'the', 'from', 'off', 'co', 'because', 'that', 'made', 'why', 'this', 'amongst', 'after', 'twenty', 'none', 'each', 'by', 'becoming', 'more', 'amoungst', 'eg', 'thereafter', 'due', 'take', 'move', 'do', 'five', 'never', 'elsewhere', 'anyhow', 'ie', 'without', 'part', 'call', 'interest', 'see', 'often', 'how', 'per', 'for', 'hereby', 'what', 'neither', 'thick', 'hundred', 'became', 'whom', 'throughout', 'towards', 'thence', 'put', 'besides', 'third', 'being', 'almost', 'over', 'bottom', 'meanwhile', 'not', 'us', 'nowhere', 'seemed', 'i', 'mill', 'otherwise', 'every', 'into', 'four', 'if', 'first', 'behind', 'fifty', 'once', 'wherein', 'own', 'others', 'beside', 'fifteen', 'thereupon', 'hers', 'one', 'now', 'hereupon', 'show', 'around', 'although', 'another', 'whence', 'hereafter', 'are', 'name', 'back', 'become', 'well', 'cry', 'except', 'seem', 're', 'already', 'ever', 'whereupon', 'wherever', 'down', 'always', 'toward', 'same', 'been', 'together', 'again', 'afterwards', 'under', 'between', 'un', 'therefore', 'six', 'inc', 'then', 'herself', 'bill', 'out', 'his', 'you', 'cant', 'its', 'he', 'both', 'during', 'everyone', 'most', 'system', 'they', 'have', 'upon', 'so', 'in', 'ltd', 'beforehand', 'empty', 'or', 'my', 'themselves', 'few', 'mostly', 'were', 'latterly', 'whole', 'our', 'found', 'should', 'fire', 'she', 'also', 'becomes', 'any', 'an', 'as', 'nevertheless', 'amount', 'below'}), vect__tokenizer=&lt;function tokenizer at 0x10ed679c0&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer at 0x112123e20&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'nothing', 'describe', 'latter', 'beyond', 'please', 'however', 'will', 'a', 'all', 'whoever', 'least', 'therein', 'along', 'thereby', 'further', 'get', 'whereafter', 'herein', 'yours', 'eleven', 'some', 'else', 'through', 'hasnt', 'within', 'whither', 'eight', 'would', 'fill', 'last', 'anywhere', 'go', 'very', 'much', 'before', 'still', 'seeming', 'next', 'where', 'other', 'we', 'whereas', 'has', 'anyone', 'sixty', 'must', 'who', 'about', 'at', 'enough', 'nobody', 'itself', 'ours', 'them', 'whereby', 'serious', 'whose', 'such', 'full', 'keep', 'myself', 'even', 'thin', 'via', 'ourselves', 'but', 'anyway', 'too', 'cannot', 'twelve', 'which', 'yourselves', 'your', 'something', 'everywhere', 'their', 'above', 'less', 'might', 'alone', 'two', 'can', 'side', 'be', 'nor', 'former', 'of', 'several', 'forty', 'than', 'ten', 'her', 'me', 'whenever', 'was', 'con', 'done', 'while', 'himself', 'find', 'formerly', 'namely', 'onto', 'whether', 'etc', 'to', 'sometimes', 'yet', 'everything', 'among', 'may', 'someone', 'across', 'whatever', 'and', 'nine', 'perhaps', 'since', 'against', 'thru', 'three', 'with', 'indeed', 'on', 'de', 'these', 'when', 'though', 'seems', 'sometime', 'him', 'only', 'rather', 'those', 'had', 'noone', 'there', 'could', 'sincere', 'thus', 'mine', 'many', 'detail', 'am', 'moreover', 'until', 'top', 'give', 'up', 'somehow', 'anything', 'yourself', 'is', 'either', 'somewhere', 'hence', 'here', 'it', 'front', 'no', 'couldnt', 'the', 'from', 'off', 'co', 'because', 'that', 'made', 'why', 'this', 'amongst', 'after', 'twenty', 'none', 'each', 'by', 'becoming', 'more', 'amoungst', 'eg', 'thereafter', 'due', 'take', 'move', 'do', 'five', 'never', 'elsewhere', 'anyhow', 'ie', 'without', 'part', 'call', 'interest', 'see', 'often', 'how', 'per', 'for', 'hereby', 'what', 'neither', 'thick', 'hundred', 'became', 'whom', 'throughout', 'towards', 'thence', 'put', 'besides', 'third', 'being', 'almost', 'over', 'bottom', 'meanwhile', 'not', 'us', 'nowhere', 'seemed', 'i', 'mill', 'otherwise', 'every', 'into', 'four', 'if', 'first', 'behind', 'fifty', 'once', 'wherein', 'own', 'others', 'beside', 'fifteen', 'thereupon', 'hers', 'one', 'now', 'hereupon', 'show', 'around', 'although', 'another', 'whence', 'hereafter', 'are', 'name', 'back', 'become', 'well', 'cry', 'except', 'seem', 're', 'already', 'ever', 'whereupon', 'wherever', 'down', 'always', 'toward', 'same', 'been', 'together', 'again', 'afterwards', 'under', 'between', 'un', 'therefore', 'six', 'inc', 'then', 'herself', 'bill', 'out', 'his', 'you', 'cant', 'its', 'he', 'both', 'during', 'everyone', 'most', 'system', 'they', 'have', 'upon', 'so', 'in', 'ltd', 'beforehand', 'empty', 'or', 'my', 'themselves', 'few', 'mostly', 'were', 'latterly', 'whole', 'our', 'found', 'should', 'fire', 'she', 'also', 'becomes', 'any', 'an', 'as', 'nevertheless', 'amount', 'below'}), vect__tokenizer=&lt;function tokenizer at 0x10ebf3b00&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer_porter at 0x111355080&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'nothing', 'describe', 'latter', 'beyond', 'please', 'however', 'will', 'a', 'all', 'whoever', 'least', 'therein', 'along', 'thereby', 'further', 'get', 'whereafter', 'herein', 'yours', 'eleven', 'some', 'else', 'through', 'hasnt', 'within', 'whither', 'eight', 'would', 'fill', 'last', 'anywhere', 'go', 'very', 'much', 'before', 'still', 'seeming', 'next', 'where', 'other', 'we', 'whereas', 'has', 'anyone', 'sixty', 'must', 'who', 'about', 'at', 'enough', 'nobody', 'itself', 'ours', 'them', 'whereby', 'serious', 'whose', 'such', 'full', 'keep', 'myself', 'even', 'thin', 'via', 'ourselves', 'but', 'anyway', 'too', 'cannot', 'twelve', 'which', 'yourselves', 'your', 'something', 'everywhere', 'their', 'above', 'less', 'might', 'alone', 'two', 'can', 'side', 'be', 'nor', 'former', 'of', 'several', 'forty', 'than', 'ten', 'her', 'me', 'whenever', 'was', 'con', 'done', 'while', 'himself', 'find', 'formerly', 'namely', 'onto', 'whether', 'etc', 'to', 'sometimes', 'yet', 'everything', 'among', 'may', 'someone', 'across', 'whatever', 'and', 'nine', 'perhaps', 'since', 'against', 'thru', 'three', 'with', 'indeed', 'on', 'de', 'these', 'when', 'though', 'seems', 'sometime', 'him', 'only', 'rather', 'those', 'had', 'noone', 'there', 'could', 'sincere', 'thus', 'mine', 'many', 'detail', 'am', 'moreover', 'until', 'top', 'give', 'up', 'somehow', 'anything', 'yourself', 'is', 'either', 'somewhere', 'hence', 'here', 'it', 'front', 'no', 'couldnt', 'the', 'from', 'off', 'co', 'because', 'that', 'made', 'why', 'this', 'amongst', 'after', 'twenty', 'none', 'each', 'by', 'becoming', 'more', 'amoungst', 'eg', 'thereafter', 'due', 'take', 'move', 'do', 'five', 'never', 'elsewhere', 'anyhow', 'ie', 'without', 'part', 'call', 'interest', 'see', 'often', 'how', 'per', 'for', 'hereby', 'what', 'neither', 'thick', 'hundred', 'became', 'whom', 'throughout', 'towards', 'thence', 'put', 'besides', 'third', 'being', 'almost', 'over', 'bottom', 'meanwhile', 'not', 'us', 'nowhere', 'seemed', 'i', 'mill', 'otherwise', 'every', 'into', 'four', 'if', 'first', 'behind', 'fifty', 'once', 'wherein', 'own', 'others', 'beside', 'fifteen', 'thereupon', 'hers', 'one', 'now', 'hereupon', 'show', 'around', 'although', 'another', 'whence', 'hereafter', 'are', 'name', 'back', 'become', 'well', 'cry', 'except', 'seem', 're', 'already', 'ever', 'whereupon', 'wherever', 'down', 'always', 'toward', 'same', 'been', 'together', 'again', 'afterwards', 'under', 'between', 'un', 'therefore', 'six', 'inc', 'then', 'herself', 'bill', 'out', 'his', 'you', 'cant', 'its', 'he', 'both', 'during', 'everyone', 'most', 'system', 'they', 'have', 'upon', 'so', 'in', 'ltd', 'beforehand', 'empty', 'or', 'my', 'themselves', 'few', 'mostly', 'were', 'latterly', 'whole', 'our', 'found', 'should', 'fire', 'she', 'also', 'becomes', 'any', 'an', 'as', 'nevertheless', 'amount', 'below'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10f239080&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10a91dd00&gt;, vect__use_idf=False; total time=   6.2s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}), vect__tokenizer=&lt;function tokenizer_porter at 0x110d6b740&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'above', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'whoever'}), vect__tokenizer=&lt;function tokenizer_porter at 0x112ae4540&gt;, vect__use_idf=False; total time=   0.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=frozenset({'nothing', 'describe', 'latter', 'beyond', 'please', 'however', 'will', 'a', 'all', 'whoever', 'least', 'therein', 'along', 'thereby', 'further', 'get', 'whereafter', 'herein', 'yours', 'eleven', 'some', 'else', 'through', 'hasnt', 'within', 'whither', 'eight', 'would', 'fill', 'last', 'anywhere', 'go', 'very', 'much', 'before', 'still', 'seeming', 'next', 'where', 'other', 'we', 'whereas', 'has', 'anyone', 'sixty', 'must', 'who', 'about', 'at', 'enough', 'nobody', 'itself', 'ours', 'them', 'whereby', 'serious', 'whose', 'such', 'full', 'keep', 'myself', 'even', 'thin', 'via', 'ourselves', 'but', 'anyway', 'too', 'cannot', 'twelve', 'which', 'yourselves', 'your', 'something', 'everywhere', 'their', 'above', 'less', 'might', 'alone', 'two', 'can', 'side', 'be', 'nor', 'former', 'of', 'several', 'forty', 'than', 'ten', 'her', 'me', 'whenever', 'was', 'con', 'done', 'while', 'himself', 'find', 'formerly', 'namely', 'onto', 'whether', 'etc', 'to', 'sometimes', 'yet', 'everything', 'among', 'may', 'someone', 'across', 'whatever', 'and', 'nine', 'perhaps', 'since', 'against', 'thru', 'three', 'with', 'indeed', 'on', 'de', 'these', 'when', 'though', 'seems', 'sometime', 'him', 'only', 'rather', 'those', 'had', 'noone', 'there', 'could', 'sincere', 'thus', 'mine', 'many', 'detail', 'am', 'moreover', 'until', 'top', 'give', 'up', 'somehow', 'anything', 'yourself', 'is', 'either', 'somewhere', 'hence', 'here', 'it', 'front', 'no', 'couldnt', 'the', 'from', 'off', 'co', 'because', 'that', 'made', 'why', 'this', 'amongst', 'after', 'twenty', 'none', 'each', 'by', 'becoming', 'more', 'amoungst', 'eg', 'thereafter', 'due', 'take', 'move', 'do', 'five', 'never', 'elsewhere', 'anyhow', 'ie', 'without', 'part', 'call', 'interest', 'see', 'often', 'how', 'per', 'for', 'hereby', 'what', 'neither', 'thick', 'hundred', 'became', 'whom', 'throughout', 'towards', 'thence', 'put', 'besides', 'third', 'being', 'almost', 'over', 'bottom', 'meanwhile', 'not', 'us', 'nowhere', 'seemed', 'i', 'mill', 'otherwise', 'every', 'into', 'four', 'if', 'first', 'behind', 'fifty', 'once', 'wherein', 'own', 'others', 'beside', 'fifteen', 'thereupon', 'hers', 'one', 'now', 'hereupon', 'show', 'around', 'although', 'another', 'whence', 'hereafter', 'are', 'name', 'back', 'become', 'well', 'cry', 'except', 'seem', 're', 'already', 'ever', 'whereupon', 'wherever', 'down', 'always', 'toward', 'same', 'been', 'together', 'again', 'afterwards', 'under', 'between', 'un', 'therefore', 'six', 'inc', 'then', 'herself', 'bill', 'out', 'his', 'you', 'cant', 'its', 'he', 'both', 'during', 'everyone', 'most', 'system', 'they', 'have', 'upon', 'so', 'in', 'ltd', 'beforehand', 'empty', 'or', 'my', 'themselves', 'few', 'mostly', 'were', 'latterly', 'whole', 'our', 'found', 'should', 'fire', 'she', 'also', 'becomes', 'any', 'an', 'as', 'nevertheless', 'amount', 'below'}), vect__tokenizer=&lt;function tokenizer_porter at 0x10f239080&gt;, vect__use_idf=False; total time=   0.0s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x1129eb880&gt;, vect__use_idf=False; total time=   5.6s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x110a3f880&gt;, vect__use_idf=False; total time=   5.8s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10ec53740&gt;, vect__use_idf=False; total time=   5.6s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x10ed679c0&gt;, vect__use_idf=False; total time=   4.8s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x110e879c0&gt;, vect__use_idf=False; total time=   4.9s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x113024720&gt;, vect__use_idf=False; total time=   5.6s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x113dfb100&gt;, vect__use_idf=False; total time=   5.3s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer at 0x11178b100&gt;, vect__use_idf=False; total time=   5.5s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f1149a0&gt;, vect__use_idf=False; total time=  30.8s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10fab09a0&gt;, vect__use_idf=False; total time=  30.4s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f5d09a0&gt;, vect__use_idf=False; total time=  30.6s
[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x1086b5d00&gt;, vect__use_idf=False; total time=  30.5s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=1.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f6009a0&gt;, vect__use_idf=False; total time=  31.1s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x110e2d3a0&gt;, vect__use_idf=False; total time=  30.4s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x112e70720&gt;, vect__use_idf=False; total time=  30.1s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x106fc63e0&gt;, vect__use_idf=False; total time=  29.4s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x11394c9a0&gt;, vect__use_idf=False; total time=  30.0s
[CV] END clf__C=10.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10fc1d080&gt;, vect__use_idf=False; total time=  30.0s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f1613a0&gt;, vect__use_idf=False; total time=  29.7s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x108baa3e0&gt;, vect__use_idf=False; total time=  28.4s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10f1ed3a0&gt;, vect__use_idf=False; total time=  28.8s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x10a91dd00&gt;, vect__use_idf=False; total time=  28.2s
[CV] END clf__C=100.0, clf__penalty=l2, vect__ngram_range=(1, 1), vect__norm=None, vect__stop_words=None, vect__tokenizer=&lt;function tokenizer_porter at 0x112f654e0&gt;, vect__use_idf=False; total time=  28.4s
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:490: FitFailedWarning: 
60 fits failed out of a total of 120.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'a', 'describe', 'less', 'be', 'sixty', 'only', 'side', 'its', 'cant', 'otherwise', 'hereby', 'anyone', 'somehow', 'elsewhere', 'several', 'whenever', 'thick', 'he', 'because', 'back', 'none', 'due', 'two', 'thin', 'nevertheless', 'himself', 'neither', 'thereupon', 'so', 'made', 'becoming', 'else', 'name', 'another', 'after', 'some', 'last', 'noone', 'will', 'without', 'her', 'find', 'out', 'who', 'go', 'yourselves', 'done', 'have', 'and', 'is', 'even', 'could', 'too', 'somewhere', 'alone', 'are', 'on', 'afterwards', 'below', 'top', 'beyond', 'latter', 'anywhere', 'anyhow', 'cry', 'now', 'former', 'every', 'fifteen', 'bottom', 'nothing', 'also', 'mill', 'detail', 'into', 'part', 'seems', 'least', 'hers', 'toward', 'interest', 'me', 'amongst', 'should', 'indeed', 'five', 'ten', 'whom', 'except', 'eleven', 'meanwhile', 'fire', 'therefore', 'one', 'per', 'give', 'his', 'this', 'than', 'next', 'empty', 'whereafter', 'yourself', 'whence', 'whereby', 'there', 'hereupon', 'yours', 'wherein', 'couldnt', 'my', 'during', 'together', 'others', 'being', 'still', 'seem', 'it', 'serious', 'un', 'off', 'from', 'enough', 'eg', 'might', 'at', 'how', 'amount', 'third', 'along', 'anything', 'ours', 'may', 'de', 'take', 'by', 'has', 'front', 'can', 'was', 'both', 'etc', 'very', 'themselves', 'if', 'same', 'seeming', 'the', 'their', 'ever', 'before', 'further', 'whether', 'our', 'nor', 'everywhere', 'keep', 'move', 'inc', 'through', 'with', 'beside', 'please', 'up', 'these', 'perhaps', 'call', 'since', 'among', 'whatever', 'until', 'almost', 'thereafter', 'must', 'where', 'system', 'itself', 'what', 'all', 'mostly', 'i', 'such', 'hundred', 'but', 'hasnt', 'someone', 'they', 'sincere', 'full', 'then', 'wherever', 'most', 'besides', 'get', 'mine', 'found', 'twenty', 'which', 'above', 'moreover', 'therein', 'thereby', 'herself', 'more', 'us', 'co', 'whose', 'other', 'again', 'con', 'not', 'we', 'myself', 'to', 'upon', 'amoungst', 'via', 're', 'whither', 'however', 'that', 'twelve', 'rather', 'much', 'beforehand', 'either', 'sometimes', 'eight', 'them', 'would', 'nowhere', 'fill', 'why', 'were', 'nine', 'ie', 'you', 'am', 'fifty', 'or', 'under', 'around', 'put', 'herein', 'here', 'something', 'whereas', 'towards', 'hence', 'whole', 'see', 'ltd', 'had', 'four', 'thence', 'often', 'few', 'everything', 'onto', 'as', 'never', 'your', 'she', 'whereupon', 'own', 'him', 'any', 'hereafter', 'already', 'become', 'between', 'in', 'whoever', 'behind', 'of', 'cannot', 'anyway', 'within', 'many', 'been', 'becomes', 'against', 'forty', 'three', 'show', 'down', 'though', 'across', 'bill', 'namely', 'about', 'although', 'when', 'over', 'do', 'became', 'those', 'six', 'once', 'each', 'throughout', 'yet', 'sometime', 'first', 'formerly', 'seemed', 'an', 'for', 'everyone', 'no', 'while', 'latterly', 'nobody', 'ourselves', 'always', 'thru', 'thus', 'well'}) instead.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'someone', 'within', 'over', 'also', 'under', 'further', 'were', 'nine', 'least', 'call', 'full', 'formerly', 'beyond', 'still', 'since', 'then', 'three', 'cry', 'please', 'becoming', 'how', 'against', 'around', 'whose', 'nothing', 'eight', 'here', 'why', 'below', 'six', 'all', 'seem', 're', 'ie', 'themselves', 'without', 'de', 'whole', 'always', 'myself', 'rather', 'only', 'upon', 'itself', 'becomes', 'should', 'into', 'thru', 'him', 'whereby', 'get', 'us', 'them', 'but', 'could', 'at', 'seems', 'amount', 'might', 'done', 'this', 'beside', 'bottom', 'herein', 'except', 'couldnt', 'beforehand', 'detail', 'never', 'moreover', 'more', 'seeming', 'that', 'almost', 'whoever', 'whether', 'everyone', 'hereafter', 'otherwise', 'thus', 'empty', 'indeed', 'their', 'system', 'as', 'therein', 'my', 'was', 'nobody', 'sometime', 'fifty', 'latterly', 'go', 'will', 'find', 'me', 'twelve', 'yours', 'who', 'am', 'together', 'from', 'what', 'which', 'do', 'whither', 'five', 'because', 'up', 'would', 'during', 'i', 'anywhere', 'be', 'above', 'thereafter', 'many', 'whatever', 'a', 'any', 'cannot', 'put', 'towards', 'others', 'take', 'give', 'hasnt', 'your', 'anything', 'the', 'though', 'sincere', 'thin', 'whereupon', 'third', 'made', 'former', 'meanwhile', 'it', 'have', 'so', 'back', 'ten', 'mostly', 'etc', 'inc', 'toward', 'they', 'amoungst', 'first', 'she', 'next', 'eg', 'something', 'about', 'four', 'much', 'both', 'twenty', 'afterwards', 'when', 'between', 'see', 'there', 'alone', 'yourselves', 'hence', 'fifteen', 'elsewhere', 'seemed', 'his', 'fire', 'every', 'eleven', 'if', 'some', 'by', 'perhaps', 'anyhow', 'top', 'on', 'keep', 'somewhere', 'whom', 'we', 'or', 'same', 'two', 'among', 'in', 'very', 'whenever', 'fill', 'our', 'had', 'become', 'side', 'serious', 'wherein', 'nevertheless', 'therefore', 'few', 'noone', 'move', 'now', 'neither', 'thence', 'too', 'latter', 'those', 'anyway', 'is', 'once', 'mine', 'describe', 'well', 'can', 'less', 'whence', 'of', 'co', 'himself', 'through', 'onto', 'last', 'un', 'amongst', 'may', 'has', 'thereby', 'else', 'after', 'per', 'must', 'show', 'not', 'however', 'whereafter', 'being', 'con', 'most', 'somehow', 'via', 'mill', 'herself', 'own', 'cant', 'behind', 'until', 'along', 'are', 'hundred', 'to', 'besides', 'these', 'other', 'none', 'down', 'yourself', 'again', 'before', 'name', 'out', 'nor', 'found', 'off', 'namely', 'sixty', 'her', 'due', 'its', 'hereupon', 'throughout', 'no', 'each', 'enough', 'became', 'he', 'an', 'while', 'thereupon', 'wherever', 'one', 'bill', 'although', 'part', 'thick', 'and', 'hereby', 'even', 'everything', 'sometimes', 'such', 'across', 'yet', 'already', 'ltd', 'than', 'interest', 'several', 'been', 'you', 'often', 'nowhere', 'everywhere', 'ours', 'another', 'ever', 'ourselves', 'for', 'where', 'front', 'with', 'either', 'whereas', 'anyone', 'forty', 'hers'}) instead.

--------------------------------------------------------------------------------
14 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'down', 'about', 'or', 'seem', 'whose', 'anyhow', 'and', 'out', 'across', 'side', 'some', 'very', 'their', 'eg', 'get', 'thus', 'we', 'himself', 'back', 'after', 'amoungst', 'this', 'enough', 'please', 'no', 'as', 'top', 'up', 'anything', 'each', 'less', 'towards', 'empty', 'six', 'ourselves', 'i', 'perhaps', 'another', 'third', 'whence', 'upon', 'such', 'meanwhile', 'too', 'afterwards', 'whither', 'which', 'of', 'would', 'something', 'first', 'while', 'hasnt', 'may', 'she', 'thence', 'any', 'nine', 'though', 'until', 'must', 'on', 'what', 'not', 'amount', 'under', 'bottom', 'keep', 'several', 'more', 'nowhere', 'found', 'whereas', 'noone', 'describe', 'yet', 'these', 'fifty', 'nevertheless', 'well', 'at', 'whatever', 'give', 'from', 'even', 'system', 'although', 'everywhere', 'ten', 'ours', 'wherever', 'throughout', 'due', 'he', 'has', 'since', 'thereby', 'than', 'toward', 'else', 'elsewhere', 'ltd', 'therefore', 'but', 'same', 'ever', 'per', 'now', 'every', 'take', 'find', 'most', 'only', 'without', 'you', 'my', 'front', 'otherwise', 'all', 'myself', 'yours', 'is', 'alone', 'between', 'everything', 'me', 'thru', 'who', 'hereupon', 'part', 'see', 'it', 'becoming', 'him', 'could', 'why', 'inc', 'hence', 'became', 'whole', 'themselves', 'they', 'someone', 'for', 'always', 'done', 'forty', 'here', 'become', 'none', 'cannot', 'your', 'mostly', 'mine', 'her', 'before', 'de', 'former', 'beforehand', 'two', 'somewhere', 'with', 'herself', 'whereby', 'fill', 'ie', 'eight', 'fifteen', 'rather', 'three', 'had', 'often', 'twenty', 'are', 'bill', 'however', 'latter', 'yourself', 'whether', 'hereafter', 'by', 'one', 'might', 'am', 'where', 'off', 'around', 'least', 'much', 'whom', 'eleven', 'so', 'fire', 'nor', 'already', 'further', 'again', 'do', 'a', 'sincere', 'nobody', 'can', 'when', 'etc', 'be', 'everyone', 'seemed', 'should', 'our', 'because', 'how', 'amongst', 'there', 'also', 'wherein', 'herein', 'formerly', 'last', 'beyond', 'namely', 'both', 'behind', 'move', 'being', 'serious', 'detail', 'almost', 'few', 'via', 'during', 'own', 'therein', 'beside', 'full', 'sometime', 'us', 'along', 'latterly', 'in', 'thereupon', 'call', 'were', 'its', 'hereby', 'thick', 'either', 'against', 'others', 'to', 'cant', 'hundred', 'once', 'co', 'many', 'within', 'was', 'seems', 'over', 'among', 'anywhere', 'his', 'sixty', 'nothing', 'together', 'that', 'whereafter', 'interest', 'con', 'cry', 'whoever', 're', 'been', 'mill', 'itself', 'four', 'those', 'onto', 'becomes', 'next', 'indeed', 'thin', 'except', 'whenever', 'show', 'them', 'will', 'neither', 'then', 'an', 'un', 'if', 'hers', 'twelve', 'whereupon', 'five', 'go', 'name', 'made', 'couldnt', 'other', 'the', 'sometimes', 'thereafter', 'somehow', 'still', 'besides', 'below', 'anyone', 'anyway', 'yourselves', 'have', 'moreover', 'put', 'seeming', 'into', 'through', 'never', 'above'}) instead.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'much', 'its', 'itself', 'such', 'thin', 'seeming', 'more', 'themselves', 'still', 'which', 'well', 'whence', 'please', 'herein', 'ltd', 'less', 'why', 'indeed', 'several', 'whereas', 'had', 'already', 'wherein', 'noone', 'serious', 'besides', 'nine', 'must', 'anywhere', 'ten', 'three', 'hereafter', 'do', 'everything', 'co', 'anyhow', 'how', 'hereupon', 'throughout', 'off', 'thereafter', 'un', 'somewhere', 'could', 'any', 'you', 'ever', 'whenever', 'top', 'at', 'per', 'anything', 'however', 'against', 'from', 'eg', 'his', 'even', 'my', 'find', 'someone', 'but', 'both', 'twelve', 'have', 'sometime', 'should', 'who', 'up', 'six', 'con', 'last', 'when', 'though', 'everywhere', 'found', 'enough', 'cannot', 'few', 'whereby', 'behind', 'whither', 'due', 'seems', 'for', 'next', 'something', 'wherever', 'twenty', 'done', 'own', 'namely', 'keep', 'never', 'in', 'amount', 'without', 'inc', 'call', 'me', 'being', 'into', 'not', 'thereupon', 'bill', 'of', 'sixty', 'mill', 'nevertheless', 'before', 'every', 'nobody', 'etc', 'moreover', 'same', 'be', 'yet', 'because', 'nowhere', 'empty', 'latter', 'show', 'many', 'other', 'those', 'hence', 'across', 'most', 'herself', 'all', 'our', 'has', 'amoungst', 'see', 'either', 'whereupon', 'thence', 'another', 'name', 'take', 'detail', 'ourselves', 'whatever', 'became', 'whom', 'i', 'some', 'third', 'somehow', 'by', 'an', 'none', 'were', 'very', 'seem', 'she', 'among', 'describe', 'thick', 'them', 'first', 'these', 'anyone', 'us', 'side', 'thus', 'then', 'nor', 'ours', 'further', 'sincere', 'whoever', 'if', 'around', 'the', 'himself', 'after', 'together', 'so', 'alone', 'bottom', 'him', 'former', 'your', 'back', 'beside', 'over', 'out', 'except', 'couldnt', 'above', 'almost', 'two', 'hers', 'on', 'will', 'to', 'hereby', 'whether', 'until', 'front', 'perhaps', 'part', 'de', 'becoming', 'can', 'are', 'hundred', 'their', 'beyond', 'he', 'otherwise', 'thereby', 'or', 'down', 'as', 'else', 'full', 'upon', 'meanwhile', 'they', 'onto', 'mine', 'only', 'made', 'her', 'this', 'would', 'fire', 'eight', 'within', 'here', 'myself', 'go', 'between', 'may', 'thru', 'via', 'move', 'mostly', 'and', 'formerly', 'become', 'give', 'amongst', 'whereafter', 'sometimes', 'seemed', 'ie', 'others', 'yours', 'elsewhere', 'toward', 'during', 're', 'that', 'five', 'what', 'might', 'rather', 'about', 'yourselves', 'four', 'yourself', 'now', 'fill', 'again', 'since', 'while', 'there', 'fifty', 'although', 'get', 'always', 'than', 'a', 'afterwards', 'fifteen', 'with', 'least', 'am', 'therein', 'anyway', 'cant', 'hasnt', 'eleven', 'therefore', 'we', 'forty', 'is', 'nothing', 'everyone', 'latterly', 'where', 'often', 'system', 'becomes', 'along', 'one', 'cry', 'was', 'below', 'under', 'also', 'whose', 'been', 'each', 'towards', 'it', 'whole', 'beforehand', 'interest', 'through', 'once', 'neither', 'too', 'no', 'put'}) instead.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'less', 'once', 'anywhere', 'none', 'during', 'never', 'found', 'five', 'always', 'i', 'due', 'very', 'becoming', 'beforehand', 'much', 'now', 'done', 'while', 'ltd', 'along', 'eleven', 'it', 'etc', 'who', 'couldnt', 'keep', 'a', 'alone', 'hereupon', 'yourself', 'hers', 'we', 'twelve', 'hence', 'besides', 'hereafter', 'if', 'call', 'his', 'an', 'several', 'among', 'hundred', 'whereafter', 'bottom', 'six', 'those', 'he', 'therefore', 'up', 'together', 'most', 'that', 'yourselves', 'though', 'twenty', 'therein', 'whose', 'meanwhile', 'first', 'inc', 'indeed', 'into', 'except', 'detail', 'below', 'describe', 'whenever', 'themselves', 'thence', 'although', 'them', 'formerly', 'again', 'anyway', 'whither', 'wherever', 'upon', 'itself', 'herein', 'there', 'own', 'nine', 'against', 'been', 'myself', 'same', 'become', 'somehow', 'yours', 'last', 'forty', 'fifty', 'could', 'thereupon', 'give', 'above', 'least', 'at', 'system', 'be', 'eg', 'see', 'three', 'cry', 'noone', 'than', 'few', 'per', 'must', 'amongst', 'she', 'please', 'seeming', 'seemed', 'thin', 'some', 'out', 'am', 'already', 'whereas', 'thru', 'because', 'are', 'from', 'when', 'often', 'de', 'these', 'mill', 'all', 'made', 'without', 'as', 'take', 'co', 'for', 'anyhow', 'via', 'another', 'since', 'its', 'cannot', 'either', 'or', 'whence', 'their', 'why', 'fill', 'mostly', 'neither', 'by', 'put', 'sometime', 'someone', 'is', 'yet', 'somewhere', 'hereby', 'also', 'would', 'ten', 'else', 'whatever', 'still', 'go', 'to', 'the', 'not', 'something', 'which', 'sincere', 'with', 'her', 'con', 'whom', 'any', 'around', 'empty', 'nobody', 'many', 'moreover', 'in', 'interest', 'whereupon', 'nowhere', 'four', 'thereby', 'however', 'our', 'fire', 'within', 'have', 'herself', 'mine', 'latter', 'thus', 'nevertheless', 'latterly', 'whereby', 'next', 're', 'off', 'wherein', 'even', 'whoever', 'beside', 'two', 'seems', 'might', 'others', 'became', 'throughout', 'back', 'us', 'anyone', 'un', 'himself', 'everywhere', 'here', 'anything', 'ours', 'name', 'well', 'third', 'were', 'afterwards', 'every', 'until', 'how', 'they', 'part', 'ever', 'has', 'such', 'top', 'this', 'my', 'no', 'will', 'ie', 'but', 'both', 'onto', 'almost', 'nothing', 'further', 'get', 'side', 'toward', 'whole', 'thick', 'eight', 'on', 'nor', 'sometimes', 'show', 'beyond', 'only', 'over', 'through', 'whether', 'what', 'becomes', 'former', 'each', 'cant', 'perhaps', 'where', 'enough', 'namely', 'other', 'do', 'may', 'had', 'hasnt', 'me', 'full', 'otherwise', 'about', 'one', 'should', 'thereafter', 'fifteen', 'after', 'down', 'find', 'sixty', 'more', 'across', 'too', 'move', 'behind', 'so', 'everything', 'serious', 'front', 'amount', 'then', 'can', 'and', 'between', 'ourselves', 'was', 'bill', 'seem', 'you', 'being', 'him', 'of', 'rather', 'amoungst', 'everyone', 'before', 'elsewhere', 'under', 'your', 'towards'}) instead.

--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'found', 'moreover', 'either', 'thereupon', 'otherwise', 'somehow', 'ours', 'if', 'but', 'anywhere', 'becoming', 'you', 'hasnt', 'his', 'ten', 'against', 'move', 'such', 'again', 'along', 'couldnt', 'hereupon', 'even', 'etc', 'nine', 'am', 'should', 'amoungst', 'give', 'into', 'made', 'onto', 'and', 'down', 'these', 'per', 'five', 'mostly', 'too', 'system', 'however', 'this', 'my', 'others', 'herein', 'elsewhere', 'much', 'whole', 'up', 'myself', 'whom', 'nobody', 'are', 'mill', 'interest', 'mine', 'indeed', 'why', 'formerly', 'almost', 'first', 'among', 'some', 'cannot', 'enough', 'thence', 'its', 'under', 'thick', 'latter', 'fifteen', 'not', 'everyone', 'though', 'by', 'beforehand', 'sometimes', 'former', 'yourselves', 'thereafter', 'beyond', 'anyway', 'something', 'an', 'except', 'themselves', 'eleven', 'hers', 'itself', 'been', 'can', 'herself', 'neither', 'ltd', 'upon', 'less', 'namely', 'each', 'thin', 'while', 'four', 'sincere', 'due', 'seems', 'here', 'perhaps', 'ie', 'he', 'none', 'most', 'to', 'both', 'top', 'in', 'could', 'own', 'third', 'amongst', 'through', 'hereby', 'off', 'toward', 'anyone', 'seem', 'take', 'yourself', 'throughout', 'further', 'meanwhile', 'our', 'therefore', 'via', 'there', 'she', 'go', 'it', 'become', 'seemed', 'so', 'several', 'will', 'sometime', 'bottom', 'someone', 'ourselves', 'fill', 'because', 'full', 'during', 'they', 'show', 'i', 'whenever', 'me', 're', 'would', 'often', 'whence', 'last', 'twelve', 'part', 'only', 'thru', 'once', 'anyhow', 'two', 'has', 'fire', 'other', 'as', 'find', 'himself', 'above', 'nevertheless', 'everything', 'them', 'six', 'we', 'be', 'somewhere', 'another', 'around', 'least', 'well', 'whose', 'whether', 'being', 'describe', 'eight', 'whereupon', 'than', 'please', 'noone', 'when', 'every', 'out', 'or', 'beside', 'seeming', 'inc', 'afterwards', 'might', 'whatever', 'always', 'from', 'although', 'their', 'twenty', 'more', 'below', 'hence', 'yet', 'before', 'the', 'whereas', 'do', 'behind', 'became', 'whither', 'front', 'that', 'yours', 'him', 'done', 'get', 'three', 'back', 'until', 'thus', 'empty', 'across', 'everywhere', 'forty', 'her', 'call', 'never', 'side', 'with', 'also', 'is', 'else', 'must', 'becomes', 'latterly', 'bill', 'few', 'those', 'same', 'co', 'de', 'cry', 'keep', 'at', 'after', 'sixty', 'whereafter', 'towards', 'between', 'your', 'cant', 'all', 'since', 'whereby', 'alone', 'many', 'what', 'nothing', 'for', 'hereafter', 'wherever', 'one', 'where', 'put', 'were', 'serious', 'fifty', 'without', 'eg', 'detail', 'which', 'of', 'any', 'un', 'rather', 'already', 'besides', 'next', 'nowhere', 'name', 'on', 'thereby', 'who', 'within', 'wherein', 'still', 'us', 'a', 'then', 'now', 'have', 'had', 'hundred', 'together', 'therein', 'anything', 'ever', 'amount', 'nor', 'may', 'very', 'see', 'over', 'was', 'how', 'con', 'no', 'about', 'whoever'}) instead.

--------------------------------------------------------------------------------
3 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'four', 'please', 'hundred', 'may', 'rather', 'get', 'thick', 'to', 'several', 'first', 'and', 'sixty', 'wherein', 'then', 'less', 'thereafter', 'one', 'well', 'formerly', 'hence', 'everything', 'of', 'every', 'co', 'although', 'whither', 'others', 'least', 'ever', 'with', 'whereby', 'seem', 'cry', 'her', 'his', 'ourselves', 'this', 'all', 'from', 'upon', 'even', 'often', 'among', 'therefore', 'amongst', 'three', 'most', 'done', 'nothing', 'been', 'other', 'eight', 'you', 'am', 'name', 'so', 'our', 'never', 'or', 'becomes', 'since', 'whereafter', 'herself', 'during', 'sincere', 'over', 'more', 'anyone', 'if', 'will', 'hereby', 'thin', 'interest', 'whence', 'thru', 'ten', 'nowhere', 'in', 'the', 'last', 'twelve', 'thereby', 'were', 'towards', 'these', 'whoever', 'mine', 'along', 'itself', 'within', 'that', 'now', 'un', 'themselves', 'former', 'afterwards', 'have', 'is', 'ltd', 'fifteen', 'before', 'yourselves', 'show', 'somewhere', 'up', 'yourself', 'latterly', 'across', 'why', 'eleven', 'on', 'about', 'himself', 'detail', 'amount', 'though', 'who', 'your', 'latter', 'hasnt', 'off', 'mostly', 'serious', 'can', 'down', 'beyond', 'both', 'give', 'behind', 'many', 'here', 'per', 'had', 'anyway', 'found', 'could', 'are', 'move', 'ie', 'became', 'indeed', 'same', 'elsewhere', 'keep', 'must', 'might', 'six', 'no', 'him', 'between', 'moreover', 'whatever', 'still', 'whole', 'hereupon', 'someone', 'them', 'anyhow', 'after', 'thereupon', 'wherever', 'twenty', 'would', 'there', 'else', 'whereupon', 'beside', 'fill', 'sometime', 'once', 'yours', 'inc', 'which', 'not', 'seems', 'was', 'meanwhile', 'system', 'only', 'couldnt', 'thus', 'thence', 'hereafter', 'further', 'amoungst', 'few', 'together', 'everywhere', 'because', 'nine', 'eg', 'nor', 'yet', 'bottom', 'how', 'back', 'but', 'neither', 'bill', 'he', 'it', 'already', 'through', 'five', 'via', 'find', 'under', 'de', 'whose', 'be', 'ours', 'below', 'until', 'perhaps', 'me', 'those', 'con', 'forty', 'nevertheless', 'everyone', 'its', 'describe', 'become', 'always', 'part', 'very', 'somehow', 'none', 'see', 'at', 'otherwise', 'as', 'therein', 'something', 'full', 'third', 'empty', 'into', 'fifty', 'call', 'should', 'onto', 'cant', 'front', 'noone', 'we', 'where', 'myself', 'against', 'made', 'namely', 'has', 'anywhere', 'their', 'top', 'herein', 'for', 'whereas', 'hers', 'nobody', 'mill', 'cannot', 'another', 'when', 'throughout', 'fire', 'without', 'toward', 'such', 'own', 'sometimes', 'some', 'she', 'seeming', 'besides', 'than', 'around', 'an', 'they', 'my', 'alone', 'either', 'each', 'except', 'whether', 'next', 'put', 'however', 'i', 'two', 'us', 'above', 'whom', 'beforehand', 'by', 'much', 'also', 'too', 'whenever', 'enough', 'anything', 'a', 'seemed', 'becoming', 'almost', 'out', 'etc', 'being', 'go', 'due', 'again', 'while', 'what', 'take', 'any', 're', 'do', 'side'}) instead.

--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'at', 'go', 'could', 'own', 'somewhere', 'nobody', 'top', 'made', 'who', 'why', 'further', 'over', 'in', 'eg', 'hereby', 'more', 'will', 'back', 'ten', 'any', 'onto', 'whereupon', 'always', 'us', 'together', 'yourself', 'wherever', 'without', 'beforehand', 'on', 'give', 'must', 'him', 'its', 'almost', 'besides', 'been', 'around', 'seem', 'eight', 'twelve', 'thereafter', 'un', 'are', 'elsewhere', 'their', 'bill', 'same', 'whither', 'name', 'wherein', 'while', 'beside', 'becoming', 'how', 'because', 'see', 'during', 'interest', 'sometimes', 'whether', 'couldnt', 'every', 'somehow', 'can', 'thence', 'enough', 'whereafter', 'full', 'otherwise', 'moreover', 'themselves', 'least', 'three', 'five', 'ours', 'still', 'etc', 'were', 'what', 'everything', 'first', 'off', 'few', 'behind', 'meanwhile', 'whole', 'now', 'whenever', 'forty', 'some', 'perhaps', 'whom', 'cant', 'much', 'which', 'afterwards', 'may', 'the', 'toward', 'not', 'across', 'me', 'nowhere', 'con', 'yourselves', 'therein', 'from', 'found', 'to', 'under', 'do', 'rather', 'if', 'hence', 'after', 'anyone', 'hundred', 'everyone', 'done', 'often', 'nine', 'next', 'cannot', 'for', 'none', 'de', 'might', 'they', 'as', 'cry', 'per', 'too', 'amount', 'have', 'thereupon', 'ltd', 'most', 'such', 'where', 'other', 'his', 'indeed', 'hers', 'mine', 'everywhere', 'down', 'those', 'empty', 'becomes', 'due', 'of', 'however', 'than', 'thereby', 'that', 'was', 'beyond', 'both', 'became', 'though', 'would', 'along', 'all', 'you', 'latterly', 'against', 'sixty', 'whoever', 'herein', 'four', 'put', 'part', 'by', 'system', 'co', 'namely', 'be', 'whereas', 'mill', 'fifty', 'himself', 'ourselves', 'hereafter', 'one', 'either', 'about', 'we', 'herself', 'anywhere', 'ever', 're', 'noone', 'anything', 'something', 'had', 'then', 'twenty', 'your', 'and', 'this', 'another', 'i', 'hereupon', 'front', 'mostly', 'upon', 'once', 'eleven', 'again', 'anyway', 'amongst', 'others', 'many', 'very', 'whence', 'myself', 'before', 'inc', 'someone', 'please', 'so', 'side', 'whereby', 'fifteen', 'within', 'itself', 'latter', 'describe', 'via', 'well', 'even', 'seeming', 'throughout', 'my', 'through', 'nothing', 'although', 'these', 'thin', 'also', 'below', 'yet', 'them', 'six', 'formerly', 'seemed', 'is', 'a', 'former', 'above', 'seems', 'nevertheless', 'whose', 'therefore', 'thick', 'else', 'it', 'yours', 'already', 'here', 'her', 'alone', 'up', 'several', 'last', 'until', 'there', 'move', 'our', 'or', 'fire', 'sincere', 'no', 'she', 'since', 'hasnt', 'only', 'less', 'take', 'he', 'out', 'keep', 'when', 'except', 'an', 'two', 'serious', 'anyhow', 'amoungst', 'am', 'between', 'thru', 'fill', 'among', 'has', 'become', 'thus', 'find', 'get', 'bottom', 'never', 'should', 'detail', 'with', 'nor', 'towards', 'but', 'call', 'ie', 'each', 'sometime', 'being', 'third', 'neither', 'show', 'whatever', 'into'}) instead.

--------------------------------------------------------------------------------
6 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'nothing', 'describe', 'latter', 'beyond', 'please', 'however', 'will', 'a', 'all', 'whoever', 'least', 'therein', 'along', 'thereby', 'further', 'get', 'whereafter', 'herein', 'yours', 'eleven', 'some', 'else', 'through', 'hasnt', 'within', 'whither', 'eight', 'would', 'fill', 'last', 'anywhere', 'go', 'very', 'much', 'before', 'still', 'seeming', 'next', 'where', 'other', 'we', 'whereas', 'has', 'anyone', 'sixty', 'must', 'who', 'about', 'at', 'enough', 'nobody', 'itself', 'ours', 'them', 'whereby', 'serious', 'whose', 'such', 'full', 'keep', 'myself', 'even', 'thin', 'via', 'ourselves', 'but', 'anyway', 'too', 'cannot', 'twelve', 'which', 'yourselves', 'your', 'something', 'everywhere', 'their', 'above', 'less', 'might', 'alone', 'two', 'can', 'side', 'be', 'nor', 'former', 'of', 'several', 'forty', 'than', 'ten', 'her', 'me', 'whenever', 'was', 'con', 'done', 'while', 'himself', 'find', 'formerly', 'namely', 'onto', 'whether', 'etc', 'to', 'sometimes', 'yet', 'everything', 'among', 'may', 'someone', 'across', 'whatever', 'and', 'nine', 'perhaps', 'since', 'against', 'thru', 'three', 'with', 'indeed', 'on', 'de', 'these', 'when', 'though', 'seems', 'sometime', 'him', 'only', 'rather', 'those', 'had', 'noone', 'there', 'could', 'sincere', 'thus', 'mine', 'many', 'detail', 'am', 'moreover', 'until', 'top', 'give', 'up', 'somehow', 'anything', 'yourself', 'is', 'either', 'somewhere', 'hence', 'here', 'it', 'front', 'no', 'couldnt', 'the', 'from', 'off', 'co', 'because', 'that', 'made', 'why', 'this', 'amongst', 'after', 'twenty', 'none', 'each', 'by', 'becoming', 'more', 'amoungst', 'eg', 'thereafter', 'due', 'take', 'move', 'do', 'five', 'never', 'elsewhere', 'anyhow', 'ie', 'without', 'part', 'call', 'interest', 'see', 'often', 'how', 'per', 'for', 'hereby', 'what', 'neither', 'thick', 'hundred', 'became', 'whom', 'throughout', 'towards', 'thence', 'put', 'besides', 'third', 'being', 'almost', 'over', 'bottom', 'meanwhile', 'not', 'us', 'nowhere', 'seemed', 'i', 'mill', 'otherwise', 'every', 'into', 'four', 'if', 'first', 'behind', 'fifty', 'once', 'wherein', 'own', 'others', 'beside', 'fifteen', 'thereupon', 'hers', 'one', 'now', 'hereupon', 'show', 'around', 'although', 'another', 'whence', 'hereafter', 'are', 'name', 'back', 'become', 'well', 'cry', 'except', 'seem', 're', 'already', 'ever', 'whereupon', 'wherever', 'down', 'always', 'toward', 'same', 'been', 'together', 'again', 'afterwards', 'under', 'between', 'un', 'therefore', 'six', 'inc', 'then', 'herself', 'bill', 'out', 'his', 'you', 'cant', 'its', 'he', 'both', 'during', 'everyone', 'most', 'system', 'they', 'have', 'upon', 'so', 'in', 'ltd', 'beforehand', 'empty', 'or', 'my', 'themselves', 'few', 'mostly', 'were', 'latterly', 'whole', 'our', 'found', 'should', 'fire', 'she', 'also', 'becomes', 'any', 'an', 'as', 'nevertheless', 'amount', 'below'}) instead.

--------------------------------------------------------------------------------
11 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'along', 'because', 'found', 'fire', 'who', 'four', 'she', 'their', 'each', 'same', 'always', 'my', 'everywhere', 'all', 'herself', 'one', 'thereupon', 'inc', 'whose', 'there', 'whence', 'below', 'do', 'onto', 'nevertheless', 'forty', 'that', 'least', 'anyhow', 'ours', 'amoungst', 'etc', 'but', 'between', 'towards', 'any', 'to', 'upon', 'ourselves', 'should', 'whereby', 'alone', 'whom', 'noone', 'much', 'eleven', 'detail', 'anywhere', 'now', 'though', 'seemed', 'name', 'cry', 'never', 'your', 'until', 'perhaps', 'except', 'being', 'whatever', 'again', 'others', 'since', 'in', 'thin', 'per', 'next', 'another', 'became', 'system', 'you', 'former', 'sometime', 'bottom', 'with', 'fifteen', 'it', 'although', 'as', 'across', 'otherwise', 're', 'into', 'enough', 'they', 'own', 'becoming', 'over', 'also', 'at', 'interest', 'six', 'among', 'a', 'anyone', 'couldnt', 'from', 'above', 'once', 'had', 'almost', 'seems', 'when', 'many', 'mine', 'two', 'we', 'no', 'nobody', 'therefore', 'me', 'has', 'sometimes', 'itself', 'the', 'made', 'without', 'by', 'bill', 'her', 'ie', 'please', 'here', 'around', 'wherein', 'seeming', 'beside', 'describe', 'meanwhile', 'often', 'ten', 'first', 'several', 'why', 'whither', 'sincere', 'up', 'sixty', 'throughout', 'anything', 'would', 'twelve', 'than', 'his', 'other', 'an', 'show', 'keep', 'themselves', 'was', 'under', 'are', 'therein', 'whoever', 'our', 'toward', 'while', 'down', 'how', 'mill', 'within', 'whereupon', 'already', 'out', 'very', 'third', 'him', 'yourself', 'himself', 'somehow', 'not', 'were', 'wherever', 'might', 'most', 'still', 'everyone', 'of', 'cannot', 'neither', 'nine', 'twenty', 'take', 'see', 'someone', 'call', 'due', 'latterly', 'this', 'top', 'few', 'get', 'have', 'de', 'ever', 'where', 'afterwards', 'fifty', 'formerly', 'behind', 'us', 'been', 'such', 'yourselves', 'eg', 'further', 'more', 'nothing', 'mostly', 'full', 'he', 'during', 'herein', 'via', 'before', 'nowhere', 'empty', 'namely', 'thereby', 'fill', 'three', 'so', 'thus', 'whole', 'con', 'some', 'am', 'and', 'will', 'anyway', 'both', 'these', 'those', 'is', 'beyond', 'serious', 'co', 'then', 'myself', 'even', 'its', 'else', 'nor', 'together', 'beforehand', 'part', 'last', 'front', 'none', 'or', 'if', 'whenever', 'what', 'amongst', 'find', 'could', 'go', 'must', 'be', 'move', 'put', 'them', 'thick', 'give', 'thereafter', 'five', 'eight', 'thru', 'however', 'elsewhere', 'hasnt', 'hereafter', 'less', 'seem', 'side', 'become', 'on', 'can', 'un', 'cant', 'back', 'whereafter', 'whether', 'for', 'becomes', 'only', 'hence', 'about', 'against', 'yet', 'latter', 'too', 'done', 'thence', 'may', 'yours', 'hers', 'well', 'indeed', 'hundred', 'either', 'everything', 'i', 'every', 'moreover', 'rather', 'amount', 'hereby', 'besides', 'somewhere', 'which', 'off', 'ltd', 'something', 'after', 'whereas', 'through', 'hereupon'}) instead.

--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_validation.py", line 833, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1336, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 613, in fit
    Xt = self._fit(X, y, routed_params, raw_params=params)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 547, in _fit
    X, fitted_transformer = fit_transform_one_cached(
                            ~~~~~~~~~~~~~~~~~~~~~~~~^
        cloned_transformer,
        ^^^^^^^^^^^^^^^^^^^
    ...&lt;5 lines&gt;...
        params=step_params,
        ^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/joblib/memory.py", line 326, in __call__
    return self.func(*args, **kwargs)
           ~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/pipeline.py", line 1484, in _fit_transform_one
    res = transformer.fit_transform(X, y, **params.get("fit_transform", {}))
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py", line 2104, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 1329, in wrapper
    estimator._validate_params()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/base.py", line 492, in _validate_params
    validate_parameter_constraints(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        self._parameter_constraints,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        self.get_params(deep=False),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        caller_name=self.__class__.__name__,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py", line 98, in validate_parameter_constraints
    raise InvalidParameterError(
    ...&lt;2 lines&gt;...
    )
sklearn.utils._param_validation.InvalidParameterError: The 'stop_words' parameter of TfidfVectorizer must be a str among {'english'}, an instance of 'list' or None. Got frozenset({'also', 'becoming', 'hereafter', 'further', 'such', 'as', 'two', 'sometimes', 'nothing', 'your', 'every', 'out', 'whenever', 'perhaps', 'ourselves', 'upon', 'call', 'anywhere', 'hereby', 'again', 'therein', 'bottom', 'on', 'have', 'hasnt', 'latterly', 'behind', 'get', 'this', 'several', 'empty', 'well', 'anyhow', 'latter', 'become', 'fire', 'are', 'so', 'none', 'always', 'off', 'below', 'us', 'system', 'may', 'already', 'be', 'once', 'detail', 'third', 'thereafter', 'fifteen', 'per', 'wherever', 'her', 'next', 'whereafter', 'since', 'myself', 'if', 'around', 'last', 'how', 'via', 'give', 'very', 'beforehand', 'why', 'of', 'fifty', 'move', 'might', 'must', 'whether', 'at', 'first', 'that', 'here', 'over', 'most', 'twenty', 'been', 'found', 'an', 'mill', 'still', 'amongst', 'the', 'being', 'everything', 'de', 'co', 'itself', 'hundred', 'describe', 'had', 'beside', 'ever', 'and', 'could', 'above', 'yourselves', 'somehow', 'others', 'eg', 'please', 'full', 'never', 'side', 'everywhere', 'where', 'them', 'now', 'all', 'something', 'show', 'nobody', 'with', 'someone', 'whom', 'whereas', 'he', 'six', 'somewhere', 'name', 'their', 're', 'we', 'whereby', 'besides', 'alone', 'even', 'whoever', 'less', 'namely', 'than', 'to', 'through', 'it', 'any', 'inc', 'no', 'hers', 'whose', 'among', 'everyone', 'amoungst', 'more', 'although', 'many', 'afterwards', 'from', 'but', 'another', 'bill', 'i', 'without', 'seems', 'should', 'nor', 'each', 'whither', 'eleven', 'forty', 'anything', 'cry', 'twelve', 'within', 'eight', 'became', 'un', 'would', 'mostly', 'after', 'who', 'whole', 'sixty', 'do', 'thence', 'between', 'in', 'ie', 'sincere', 'because', 'noone', 'mine', 'few', 'these', 'has', 'ten', 'under', 'am', 'together', 'enough', 'con', 'its', 'find', 'four', 'by', 'up', 'sometime', 'against', 'wherein', 'some', 'ltd', 'our', 'own', 'etc', 'hereupon', 'put', 'neither', 'interest', 'five', 'though', 'back', 'throughout', 'down', 'she', 'too', 'due', 'much', 'a', 'front', 'made', 'thru', 'except', 'themselves', 'for', 'whatever', 'often', 'seeming', 'when', 'thin', 'him', 'is', 'my', 'meanwhile', 'herself', 'moreover', 'becomes', 'beyond', 'both', 'three', 'take', 'other', 'serious', 'about', 'while', 'nevertheless', 'seem', 'formerly', 'towards', 'you', 'part', 'top', 'thick', 'toward', 'yourself', 'nine', 'either', 'whence', 'they', 'during', 'amount', 'hence', 'thereupon', 'almost', 'least', 'indeed', 'however', 'same', 'which', 'then', 'what', 'his', 'anyone', 'one', 'whereupon', 'only', 'couldnt', 'yet', 'done', 'go', 'along', 'me', 'anyway', 'cannot', 'himself', 'not', 'there', 'yours', 'elsewhere', 'were', 'see', 'was', 'fill', 'ours', 'onto', 'thus', 'herein', 'into', 'across', 'nowhere', 'seemed', 'therefore', 'rather', 'until', 'before', 'otherwise', 'thereby', 'else', 'or', 'former', 'can', 'keep', 'cant', 'will', 'those'}) instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1137: UserWarning: One or more of the test scores are non-finite: [ nan  nan 0.89 0.89  nan  nan 0.9  0.89  nan  nan 0.89 0.88  nan  nan
 0.88 0.87  nan  nan 0.88 0.87  nan  nan 0.87 0.86]
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
  warnings.warn(
/Users/shivesh/Desktop/PythonProject/Sentiment Analysis/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.
  warnings.warn(
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>CV Accuracy: 0.897
Best params: {'clf__C': 10.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': &lt;function tokenizer at 0x1123a6d40&gt;}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fc4d4672c68581bf">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Why-5-Fold-Stratified-Cross-Validation?">Why 5-Fold Stratified Cross-Validation?<a class="anchor-link" href="#Why-5-Fold-Stratified-Cross-Validation?"></a></h3><p>We use <strong>k-fold cross-validation</strong> to reduce the influence of luck in our
evaluation. Instead of relying on a single train/test split, we split the data
into <em>k</em> folds and run <em>k</em> rounds of training + validation, each time using a
different fold as the validation set. The final score is the average accuracy
across all folds.</p>
<p>For classification tasks we use <strong>StratifiedKFold</strong>, which keeps the class
distribution (positive / negative) similar in every fold. This makes each fold
representative of the full dataset.</p>
<p>Choosing <strong>5 folds instead of 10</strong> is a practical trade-off:</p>
<ul>
<li>10-fold CV has slightly lower variance in the accuracy estimate,
but takes about <strong>twice as long</strong>.</li>
<li>5-fold CV is <strong>much faster</strong> while still giving a reliable estimate.</li>
</ul>
<p>On the 50k IMDB reviews, a large grid search with 10-fold CV would be very
expensive, so the book uses <strong>5-fold stratified CV</strong> as a good balance between
runtime and robustness.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=b3ad42b6c7f8d3af">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># 5. Evaluate on the test set</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Test Accuracy: </span><span class="si">%.3f</span><span class="s2">"</span> <span class="o">%</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Test Accuracy: 0.899
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=89a4a9d8532eb860">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Out-of-Core-Learning-with-HashingVectorizer-+-SGDClassifier">Out-of-Core Learning with HashingVectorizer + SGDClassifier<a class="anchor-link" href="#Out-of-Core-Learning-with-HashingVectorizer-+-SGDClassifier"></a></h2><p>The previous grid search uses <strong>all 50,000 reviews in memory</strong> at once.
For much larger datasets, this can become too slow or memory-heavy.</p>
<p>To handle larger data, we can use <strong>out-of-core learning</strong>:</p>
<ul>
<li>Instead of loading the whole dataset, we <strong>stream</strong> documents from disk in
small mini-batches.</li>
<li>We use a classifier that supports <strong>incremental learning</strong> via <code>partial_fit</code>
(here: <code>SGDClassifier</code> with logistic loss).</li>
<li>We use <code>HashingVectorizer</code> instead of <code>CountVectorizer</code> / <code>TfidfVectorizer</code>:<ul>
<li>HashingVectorizer maps tokens to a fixed-size feature space using a hash
function.</li>
<li>It does not need to store a vocabulary, so it is very memory efficient.</li>
<li>This is ideal when we process data in a stream.</li>
</ul>
</li>
</ul>
<h3 id="Steps">Steps<a class="anchor-link" href="#Steps"></a></h3><ol>
<li><p><strong>Tokenizer function</strong></p>
<p>We reuse a text cleaning + tokenization function that:</p>
<ul>
<li>removes HTML tags and punctuation,</li>
<li>extracts emoticons,</li>
<li>lowercases text,</li>
<li>optionally removes stop words,</li>
<li>optionally applies stemming.</li>
</ul>
</li>
<li><p><strong>Document stream</strong></p>
<p>We define <code>stream_docs(path)</code>:</p>
<ul>
<li>opens <code>movie_data.csv</code>,</li>
<li>skips the header,</li>
<li>yields one <code>(text, label)</code> pair at a time.</li>
</ul>
</li>
<li><p><strong>Mini-batch function</strong></p>
<p><code>get_minibatch(doc_stream, size)</code>:</p>
<ul>
<li>pulls <code>size</code> documents from the stream,</li>
<li>returns <code>X</code> (list of text) and <code>y</code> (list/array of labels).</li>
</ul>
</li>
<li><p><strong>Model</strong></p>
<ul>
<li><code>HashingVectorizer</code> with our tokenizer and preprocessor.</li>
<li><code>SGDClassifier(loss='log_loss')</code> for online logistic regression.</li>
<li>We call <code>partial_fit</code> on each mini-batch.</li>
</ul>
</li>
</ol>
<p>We iterate, for example, over <strong>45 mini-batches</strong> of size 1,000:</p>
<ul>
<li>45  1,000 = 45,000 documents for training.</li>
<li>We keep the last 5,000 documents as a held-out test set.</li>
<li>At the end, we compute accuracy on that test set.</li>
</ul>
<p>The accuracy is slightly lower than the full grid-search model (~0.860.87 vs
~0.90), but the training is:</p>
<ul>
<li>much faster,</li>
<li>uses much less memory,</li>
<li>scalable to much larger datasets.</li>
</ul>
<p>This is the main idea behind <strong>online / streaming learning</strong> in this chapter.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=cd65ca7529533b2a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">csv</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">HashingVectorizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">ENGLISH_STOP_WORDS</span>

<span class="c1"># If not already defined, reuse our preprocessor/tokenizer here.</span>
<span class="c1"># I'll show a self-contained version which is close to the book:</span>

<span class="n">stop</span> <span class="o">=</span> <span class="n">ENGLISH_STOP_WORDS</span>

<span class="k">def</span><span class="w"> </span><span class="nf">preprocessor_stream</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># strip HTML tags</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"&lt;[^&gt;]*&gt;"</span><span class="p">,</span> <span class="s2">""</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># extract emoticons</span>
    <span class="n">emoticons</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s2">"(?::|;|=)(?:-)?(?:\)|\(|D|P)"</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

    <span class="c1"># remove non-word characters and convert to lower case</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"[\W]+"</span><span class="p">,</span> <span class="s2">" "</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

    <span class="c1"># append emoticons without hyphens</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span> <span class="o">+</span> <span class="s2">" "</span> <span class="o">+</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">emoticons</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"-"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span><span class="w"> </span><span class="nf">tokenizer_stream</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>


<span class="c1"># Document stream generator</span>

<span class="k">def</span><span class="w"> </span><span class="nf">stream_docs</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Yield (text, label) pairs from the movie_data.csv file."""</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
        <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
        <span class="nb">next</span><span class="p">(</span><span class="n">reader</span><span class="p">)</span>  <span class="c1"># skip header</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
            <span class="n">text</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">yield</span> <span class="n">text</span><span class="p">,</span> <span class="n">label</span>


<span class="c1"># Minibatch helper</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_minibatch</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Read `size` documents from the stream."""</span>
    <span class="n">docs</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
            <span class="n">text</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">)</span>
            <span class="n">docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">docs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>


<span class="c1"># HashingVectorizer + SGDClassifier</span>

<span class="n">vect</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span>
    <span class="n">decode_error</span><span class="o">=</span><span class="s2">"ignore"</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">21</span><span class="p">,</span>           <span class="c1"># as in the book</span>
    <span class="n">preprocessor</span><span class="o">=</span><span class="n">preprocessor_stream</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer_stream</span>
<span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="s2">"log_loss"</span><span class="p">,</span>            <span class="c1"># logistic regression</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1</span>                  <span class="c1"># we'll control epochs via partial_fit</span>
<span class="p">)</span>

<span class="n">doc_stream</span> <span class="o">=</span> <span class="n">stream_docs</span><span class="p">(</span><span class="s2">"movie_data.csv"</span><span class="p">)</span>

<span class="c1"># Classes need to be passed for the first call to partial_fit</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>


<span class="c1"># Online training on 45 mini-batches of 1,000 docs each</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pyprind</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProgBar</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgBar</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">45</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">get_minibatch</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">X_train</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>


<span class="c1"># Evaluate on the remaining 5,000 docs</span>

<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">get_minibatch</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Accuracy: </span><span class="si">%.3f</span><span class="s2">"</span> <span class="o">%</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="c1"># Optionally, update the model one last time on the test set</span>
<span class="n">clf</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Warning: No valid output stream.
Accuracy: 0.830
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[21]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;
}

#sk-container-id-1.light {
  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: black;
  --sklearn-color-background: white;
  --sklearn-color-border-box: black;
  --sklearn-color-icon: #696969;
}

#sk-container-id-1.dark {
  --sklearn-color-text-on-default-background: white;
  --sklearn-color-background: #111;
  --sklearn-color-border-box: white;
  --sklearn-color-icon: #878787;
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: center;
  justify-content: center;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-3) 1pt solid;
  color: var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3) 1pt solid;
  color: var(--sklearn-color-fitted-level-3);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-unfitted-level-0);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-fitted-level-0);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table {
    font-family: monospace;
}

.estimator-table summary {
    padding: .5rem;
    cursor: pointer;
}

.estimator-table summary::marker {
    font-size: 0.7rem;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
    margin-top: 0;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

/*
    `table td`is set in notebook with right text-align.
    We need to overwrite it.
*/
.estimator-table table td.param {
    text-align: left;
    position: relative;
    padding: 0;
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left !important;
}

.user-set td.value {
    color:rgb(255, 94, 0);
    background-color: transparent;
}

.default td {
    color: black;
    text-align: left !important;
}

.user-set td i,
.default td i {
    color: black;
}

/*
    Styles for parameter documentation links
    We need styling for visited so jupyter doesn't overwrite it
*/
a.param-doc-link,
a.param-doc-link:link,
a.param-doc-link:visited {
    text-decoration: underline dashed;
    text-underline-offset: .3em;
    color: inherit;
    display: block;
    padding: .5em;
}

/* "hack" to make the entire area of the cell containing the link clickable */
a.param-doc-link::before {
    position: absolute;
    content: "";
    inset: 0;
}

.param-doc-description {
    display: none;
    position: absolute;
    z-index: 9999;
    left: 0;
    padding: .5ex;
    margin-left: 1.5em;
    color: var(--sklearn-color-text);
    box-shadow: .3em .3em .4em #999;
    width: max-content;
    text-align: left;
    max-height: 10em;
    overflow-y: auto;

    /* unfitted */
    background: var(--sklearn-color-unfitted-level-0);
    border: thin solid var(--sklearn-color-unfitted-level-3);
}

/* Fitted state for parameter tooltips */
.fitted .param-doc-description {
    /* fitted */
    background: var(--sklearn-color-fitted-level-0);
    border: thin solid var(--sklearn-color-fitted-level-3);
}

.param-doc-link:hover .param-doc-description {
    display: block;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><body><div class="sk-top-container" id="sk-container-id-1"><div class="sk-text-repr-fallback"><pre>SGDClassifier(loss='log_loss', max_iter=1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br/>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input checked="" class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"/><label class="sk-toggleable__label fitted sk-toggleable__label-arrow" for="sk-estimator-id-1"><div><div>SGDClassifier</div></div><div><a class="sk-estimator-doc-link fitted" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html" rel="noreferrer" target="_blank">?<span>Documentation for SGDClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
<div class="estimator-table">
<details>
<summary>Parameters</summary>
<table class="parameters-table">
<tbody>
<tr class="user-set">
<td><i class="copy-paste-icon" onclick="copyToClipboard('loss',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=loss,-%7B%27hinge%27%2C%20%27log_loss%27%2C%20%27modified_huber%27%2C%20%27squared_hinge%27%2C%20%20%20%20%20%20%20%20%27perceptron%27%2C%20%27squared_error%27%2C%20%27huber%27%2C%20%27epsilon_insensitive%27%2C%20%20%20%20%20%20%20%20%27squared_epsilon_insensitive%27%7D%2C%20default%3D%27hinge%27" rel="noreferrer" target="_blank">
            loss
            <span class="param-doc-description">loss: {'hinge', 'log_loss', 'modified_huber', 'squared_hinge',        'perceptron', 'squared_error', 'huber', 'epsilon_insensitive',        'squared_epsilon_insensitive'}, default='hinge'<br/><br/>The loss function to be used.<br/><br/>- 'hinge' gives a linear SVM.<br/>- 'log_loss' gives logistic regression, a probabilistic classifier.<br/>- 'modified_huber' is another smooth loss that brings tolerance to<br/>  outliers as well as probability estimates.<br/>- 'squared_hinge' is like hinge but is quadratically penalized.<br/>- 'perceptron' is the linear loss used by the perceptron algorithm.<br/>- The other losses, 'squared_error', 'huber', 'epsilon_insensitive' and<br/>  'squared_epsilon_insensitive' are designed for regression but can be useful<br/>  in classification as well; see<br/>  :class:`~sklearn.linear_model.SGDRegressor` for a description.<br/><br/>More details about the losses formulas can be found in the :ref:`User Guide<br/><sgd_mathematical_formulation>` and you can find a visualisation of the loss<br/>functions in<br/>:ref:`sphx_glr_auto_examples_linear_model_plot_sgd_loss_functions.py`.</sgd_mathematical_formulation></span>
</a>
</td>
<td class="value">'log_loss'</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('penalty',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=penalty,-%7B%27l2%27%2C%20%27l1%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27" rel="noreferrer" target="_blank">
            penalty
            <span class="param-doc-description">penalty: {'l2', 'l1', 'elasticnet', None}, default='l2'<br/><br/>The penalty (aka regularization term) to be used. Defaults to 'l2'<br/>which is the standard regularizer for linear SVM models. 'l1' and<br/>'elasticnet' might bring sparsity to the model (feature selection)<br/>not achievable with 'l2'. No penalty is added when set to `None`.<br/><br/>You can see a visualisation of the penalties in<br/>:ref:`sphx_glr_auto_examples_linear_model_plot_sgd_penalties.py`.</span>
</a>
</td>
<td class="value">'l2'</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('alpha',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=alpha,-float%2C%20default%3D0.0001" rel="noreferrer" target="_blank">
            alpha
            <span class="param-doc-description">alpha: float, default=0.0001<br/><br/>Constant that multiplies the regularization term. The higher the<br/>value, the stronger the regularization. Also used to compute the<br/>learning rate when `learning_rate` is set to 'optimal'.<br/>Values must be in the range `[0.0, inf)`.</span>
</a>
</td>
<td class="value">0.0001</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('l1_ratio',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=l1_ratio,-float%2C%20default%3D0.15" rel="noreferrer" target="_blank">
            l1_ratio
            <span class="param-doc-description">l1_ratio: float, default=0.15<br/><br/>The Elastic Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1.<br/>l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.<br/>Only used if `penalty` is 'elasticnet'.<br/>Values must be in the range `[0.0, 1.0]` or can be `None` if<br/>`penalty` is not `elasticnet`.<br/><br/>.. versionchanged:: 1.7<br/>    `l1_ratio` can be `None` when `penalty` is not "elasticnet".</span>
</a>
</td>
<td class="value">0.15</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('fit_intercept',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue" rel="noreferrer" target="_blank">
            fit_intercept
            <span class="param-doc-description">fit_intercept: bool, default=True<br/><br/>Whether the intercept should be estimated or not. If False, the<br/>data is assumed to be already centered.</span>
</a>
</td>
<td class="value">True</td>
</tr>
<tr class="user-set">
<td><i class="copy-paste-icon" onclick="copyToClipboard('max_iter',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=max_iter,-int%2C%20default%3D1000" rel="noreferrer" target="_blank">
            max_iter
            <span class="param-doc-description">max_iter: int, default=1000<br/><br/>The maximum number of passes over the training data (aka epochs).<br/>It only impacts the behavior in the ``fit`` method, and not the<br/>:meth:`partial_fit` method.<br/>Values must be in the range `[1, inf)`.<br/><br/>.. versionadded:: 0.19</span>
</a>
</td>
<td class="value">1</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('tol',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=tol,-float%20or%20None%2C%20default%3D1e-3" rel="noreferrer" target="_blank">
            tol
            <span class="param-doc-description">tol: float or None, default=1e-3<br/><br/>The stopping criterion. If it is not None, training will stop<br/>when (loss &gt; best_loss - tol) for ``n_iter_no_change`` consecutive<br/>epochs.<br/>Convergence is checked against the training loss or the<br/>validation loss depending on the `early_stopping` parameter.<br/>Values must be in the range `[0.0, inf)`.<br/><br/>.. versionadded:: 0.19</span>
</a>
</td>
<td class="value">0.001</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('shuffle',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=shuffle,-bool%2C%20default%3DTrue" rel="noreferrer" target="_blank">
            shuffle
            <span class="param-doc-description">shuffle: bool, default=True<br/><br/>Whether or not the training data should be shuffled after each epoch.</span>
</a>
</td>
<td class="value">True</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('verbose',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=verbose,-int%2C%20default%3D0" rel="noreferrer" target="_blank">
            verbose
            <span class="param-doc-description">verbose: int, default=0<br/><br/>The verbosity level.<br/>Values must be in the range `[0, inf)`.</span>
</a>
</td>
<td class="value">0</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('epsilon',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=epsilon,-float%2C%20default%3D0.1" rel="noreferrer" target="_blank">
            epsilon
            <span class="param-doc-description">epsilon: float, default=0.1<br/><br/>Epsilon in the epsilon-insensitive loss functions; only if `loss` is<br/>'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.<br/>For 'huber', determines the threshold at which it becomes less<br/>important to get the prediction exactly right.<br/>For epsilon-insensitive, any differences between the current prediction<br/>and the correct label are ignored if they are less than this threshold.<br/>Values must be in the range `[0.0, inf)`.</span>
</a>
</td>
<td class="value">0.1</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('n_jobs',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone" rel="noreferrer" target="_blank">
            n_jobs
            <span class="param-doc-description">n_jobs: int, default=None<br/><br/>The number of CPUs to use to do the OVA (One Versus All, for<br/>multi-class problems) computation.<br/>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br/>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br/>for more details.</n_jobs></span>
</a>
</td>
<td class="value">None</td>
</tr>
<tr class="user-set">
<td><i class="copy-paste-icon" onclick="copyToClipboard('random_state',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone" rel="noreferrer" target="_blank">
            random_state
            <span class="param-doc-description">random_state: int, RandomState instance, default=None<br/><br/>Used for shuffling the data, when ``shuffle`` is set to ``True``.<br/>Pass an int for reproducible output across multiple function calls.<br/>See :term:`Glossary <random_state>`.<br/>Integer values must be in the range `[0, 2**32 - 1]`.</random_state></span>
</a>
</td>
<td class="value">1</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('learning_rate',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=learning_rate,-str%2C%20default%3D%27optimal%27" rel="noreferrer" target="_blank">
            learning_rate
            <span class="param-doc-description">learning_rate: str, default='optimal'<br/><br/>The learning rate schedule:<br/><br/>- 'constant': `eta = eta0`<br/>- 'optimal': `eta = 1.0 / (alpha * (t + t0))`<br/>  where `t0` is chosen by a heuristic proposed by Leon Bottou.<br/>- 'invscaling': `eta = eta0 / pow(t, power_t)`<br/>- 'adaptive': `eta = eta0`, as long as the training keeps decreasing.<br/>  Each time n_iter_no_change consecutive epochs fail to decrease the<br/>  training loss by tol or fail to increase validation score by tol if<br/>  `early_stopping` is `True`, the current learning rate is divided by 5.<br/>- 'pa1': passive-aggressive algorithm 1, see [1]_. Only with `loss='hinge'`.<br/>  Update is `w += eta y x` with `eta = min(eta0, loss/||x||**2)`.<br/>- 'pa2': passive-aggressive algorithm 2, see [1]_. Only with<br/>  `loss='hinge'`.<br/>  Update is `w += eta y x` with `eta = hinge_loss / (||x||**2 + 1/(2 eta0))`.<br/><br/>.. versionadded:: 0.20<br/>    Added 'adaptive' option.<br/><br/>.. versionadded:: 1.8<br/>   Added options 'pa1' and 'pa2'</span>
</a>
</td>
<td class="value">'optimal'</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('eta0',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=eta0,-float%2C%20default%3D0.01" rel="noreferrer" target="_blank">
            eta0
            <span class="param-doc-description">eta0: float, default=0.01<br/><br/>The initial learning rate for the 'constant', 'invscaling' or<br/>'adaptive' schedules. The default value is 0.01, but note that eta0 is not used<br/>by the default learning rate 'optimal'.<br/>Values must be in the range `(0.0, inf)`.<br/><br/>For PA-1 (`learning_rate=pa1`) and PA-II (`pa2`), it specifies the<br/>aggressiveness parameter for the passive-agressive algorithm, see [1] where it<br/>is called C:<br/><br/>- For PA-I it is the maximum step size.<br/>- For PA-II it regularizes the step size (the smaller `eta0` the more it<br/>  regularizes).<br/><br/>As a general rule-of-thumb for PA, `eta0` should be small when the data is<br/>noisy.</span>
</a>
</td>
<td class="value">0.01</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('power_t',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=power_t,-float%2C%20default%3D0.5" rel="noreferrer" target="_blank">
            power_t
            <span class="param-doc-description">power_t: float, default=0.5<br/><br/>The exponent for inverse scaling learning rate.<br/>Values must be in the range `[0.0, inf)`.<br/><br/>.. deprecated:: 1.8<br/>    Negative values for `power_t` are deprecated in version 1.8 and will raise<br/>    an error in 1.10. Use values in the range [0.0, inf) instead.</span>
</a>
</td>
<td class="value">0.5</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('early_stopping',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=early_stopping,-bool%2C%20default%3DFalse" rel="noreferrer" target="_blank">
            early_stopping
            <span class="param-doc-description">early_stopping: bool, default=False<br/><br/>Whether to use early stopping to terminate training when validation<br/>score is not improving. If set to `True`, it will automatically set aside<br/>a stratified fraction of training data as validation and terminate<br/>training when validation score returned by the `score` method is not<br/>improving by at least tol for n_iter_no_change consecutive epochs.<br/><br/>See :ref:`sphx_glr_auto_examples_linear_model_plot_sgd_early_stopping.py` for an<br/>example of the effects of early stopping.<br/><br/>.. versionadded:: 0.20<br/>    Added 'early_stopping' option</span>
</a>
</td>
<td class="value">False</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('validation_fraction',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=validation_fraction,-float%2C%20default%3D0.1" rel="noreferrer" target="_blank">
            validation_fraction
            <span class="param-doc-description">validation_fraction: float, default=0.1<br/><br/>The proportion of training data to set aside as validation set for<br/>early stopping. Must be between 0 and 1.<br/>Only used if `early_stopping` is True.<br/>Values must be in the range `(0.0, 1.0)`.<br/><br/>.. versionadded:: 0.20<br/>    Added 'validation_fraction' option</span>
</a>
</td>
<td class="value">0.1</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('n_iter_no_change',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=n_iter_no_change,-int%2C%20default%3D5" rel="noreferrer" target="_blank">
            n_iter_no_change
            <span class="param-doc-description">n_iter_no_change: int, default=5<br/><br/>Number of iterations with no improvement to wait before stopping<br/>fitting.<br/>Convergence is checked against the training loss or the<br/>validation loss depending on the `early_stopping` parameter.<br/>Integer values must be in the range `[1, max_iter)`.<br/><br/>.. versionadded:: 0.20<br/>    Added 'n_iter_no_change' option</span>
</a>
</td>
<td class="value">5</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('class_weight',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=class_weight,-dict%2C%20%7Bclass_label%3A%20weight%7D%20or%20%22balanced%22%2C%20default%3DNone" rel="noreferrer" target="_blank">
            class_weight
            <span class="param-doc-description">class_weight: dict, {class_label: weight} or "balanced", default=None<br/><br/>Preset for the class_weight fit parameter.<br/><br/>Weights associated with classes. If not given, all classes<br/>are supposed to have weight one.<br/><br/>The "balanced" mode uses the values of y to automatically adjust<br/>weights inversely proportional to class frequencies in the input data<br/>as ``n_samples / (n_classes * np.bincount(y))``.</span>
</a>
</td>
<td class="value">None</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('warm_start',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse" rel="noreferrer" target="_blank">
            warm_start
            <span class="param-doc-description">warm_start: bool, default=False<br/><br/>When set to True, reuse the solution of the previous call to fit as<br/>initialization, otherwise, just erase the previous solution.<br/>See :term:`the Glossary <warm_start>`.<br/><br/>Repeatedly calling fit or partial_fit when warm_start is True can<br/>result in a different solution than when calling fit a single time<br/>because of the way the data is shuffled.<br/>If a dynamic learning rate is used, the learning rate is adapted<br/>depending on the number of samples already seen. Calling ``fit`` resets<br/>this counter, while ``partial_fit`` will result in increasing the<br/>existing counter.</warm_start></span>
</a>
</td>
<td class="value">False</td>
</tr>
<tr class="default">
<td><i class="copy-paste-icon" onclick="copyToClipboard('average',
                          this.parentElement.nextElementSibling)"></i></td>
<td class="param">
<a class="param-doc-link" href="https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.SGDClassifier.html#:~:text=average,-bool%20or%20int%2C%20default%3DFalse" rel="noreferrer" target="_blank">
            average
            <span class="param-doc-description">average: bool or int, default=False<br/><br/>When set to `True`, computes the averaged SGD weights across all<br/>updates and stores the result in the ``coef_`` attribute. If set to<br/>an int greater than 1, averaging will begin once the total number of<br/>samples seen reaches `average`. So ``average=10`` will begin<br/>averaging after seeing 10 samples.<br/>Integer values must be in the range `[1, n_samples]`.</span>
</a>
</td>
<td class="value">False</td>
</tr>
</tbody>
</table>
</details>
</div>
</div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.copy-paste-icon').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling
        .textContent.trim().split(' ')[0];
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});


/**
 * Adapted from Skrub
 * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789
 * @returns "light" or "dark"
 */
function detectTheme(element) {
    const body = document.querySelector('body');

    // Check VSCode theme
    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');
    const themeNameAttr = body.getAttribute('data-vscode-theme-name');

    if (themeKindAttr && themeNameAttr) {
        const themeKind = themeKindAttr.toLowerCase();
        const themeName = themeNameAttr.toLowerCase();

        if (themeKind.includes("dark") || themeName.includes("dark")) {
            return "dark";
        }
        if (themeKind.includes("light") || themeName.includes("light")) {
            return "light";
        }
    }

    // Check Jupyter theme
    if (body.getAttribute('data-jp-theme-light') === 'false') {
        return 'dark';
    } else if (body.getAttribute('data-jp-theme-light') === 'true') {
        return 'light';
    }

    // Guess based on a parent element's color
    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');
    const match = color.match(/^rgb\s*\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)\s*$/i);
    if (match) {
        const [r, g, b] = [
            parseFloat(match[1]),
            parseFloat(match[2]),
            parseFloat(match[3])
        ];

        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness
        const luma = 0.299 * r + 0.587 * g + 0.114 * b;

        if (luma > 180) {
            // If the text is very bright we have a dark theme
            return 'dark';
        }
        if (luma < 75) {
            // If the text is very dark we have a light theme
            return 'light';
        }
        // Otherwise fall back to the next heuristic.
    }

    // Fallback to system preference
    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
}


function forceTheme(elementId) {
    const estimatorElement = document.querySelector(`#${elementId}`);
    if (estimatorElement === null) {
        console.error(`Element with id ${elementId} not found.`);
    } else {
        const theme = detectTheme(estimatorElement);
        estimatorElement.classList.add(theme);
    }
}

forceTheme('sk-container-id-1');</script></body>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a514250393293642">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Naive-Bayes-Classifier-(short-note)">Naive Bayes Classifier (short note)<a class="anchor-link" href="#Naive-Bayes-Classifier-(short-note)"></a></h2><p>The chapter briefly mentions the <strong>naive Bayes classifier</strong> as another popular
text classification model.</p>
<p>Key points:</p>
<ul>
<li>Very simple and fast to train.</li>
<li>Assumes features are <strong>conditionally independent</strong> given the class.</li>
<li>Works surprisingly well on many text tasks (e.g. spam filtering).</li>
<li>Often used as a strong baseline, especially with Bag-of-Words features.</li>
</ul>
<p>We are not implementing naive Bayes here, but the idea is:</p>
<ol>
<li>Estimate <strong>P(word | class)</strong> from the training corpus.</li>
<li>For a new document, combine word probabilities to compute <strong>P(class | doc)</strong>.</li>
<li>Choose the class with the higher posterior probability.</li>
</ol>
<hr/>
<h2 id="word2vec-(short-note)">word2vec (short note)<a class="anchor-link" href="#word2vec-(short-note)"></a></h2><p>The book also mentions <strong>word2vec</strong> as a more modern alternative to
Bag-of-Words:</p>
<ul>
<li>Instead of representing words as one-hot vectors, word2vec learns
<strong>dense, low-dimensional embeddings</strong>.</li>
<li>Words with similar meanings end up close together in this vector space.</li>
<li>Famous examples: <strong>king &gt; man</strong> and  <strong>woman -&gt; queen</strong>.</li>
</ul>
<p>In this chapter we just note that:</p>
<ul>
<li>word2vec (and more modern methods like GloVe, fastText, and transformers)
can capture <strong>semantic relationships</strong> that Bag-of-Words cannot.</li>
<li>Later chapters (and other resources) cover neural-network-based models
in more detail.</li>
</ul>
<p>For the IMDB sentiment project here, we stick to Bag-of-Words / TF-IDF +
linear models (logistic regression / SGD).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=30d828888451751b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Topic-Modelling-with-Latent-Dirichlet-Allocation-(LDA)">Topic Modelling with Latent Dirichlet Allocation (LDA)<a class="anchor-link" href="#Topic-Modelling-with-Latent-Dirichlet-Allocation-(LDA)"></a></h2><p>So far we have focused on <strong>supervised learning</strong>: predicting the sentiment
label (positive/negative) given a review.</p>
<p>In this section, we switch to an <strong>unsupervised</strong> task: <strong>topic modelling</strong>.</p>
<h3 id="What-is-LDA?">What is LDA?<a class="anchor-link" href="#What-is-LDA?"></a></h3><p><strong>Latent Dirichlet Allocation (LDA)</strong> is a generative probabilistic model that
tries to discover <strong>hidden topics</strong> in a document collection by looking at how
words co-occur across documents.</p>
<ul>
<li>Each <strong>document</strong> is modelled as a mixture of topics.</li>
<li>Each <strong>topic</strong> is a distribution over words.</li>
</ul>
<p>Given a <strong>bag-of-words matrix</strong> (documents  words), LDA decomposes it into:</p>
<ul>
<li>a document-to-topic matrix (how much each topic contributes to a document),</li>
<li>a topic-to-word matrix (how strongly each word belongs to each topic).</li>
</ul>
<p>We must <strong>choose the number of topics</strong> in advance (here: 10). This is a
hyperparameter and can be tuned.</p>
<h3 id="LDA-with-scikit-learn">LDA with scikit-learn<a class="anchor-link" href="#LDA-with-scikit-learn"></a></h3><p>Steps from the textbook:</p>
<ol>
<li>Load <code>movie_data.csv</code> into a DataFrame <code>df</code>.</li>
<li>Use <code>CountVectorizer</code> to create a bag-of-words matrix <code>X</code>:<ul>
<li>remove very common words (<code>max_df=0.1</code>  ignore words in &gt;10% of docs),</li>
<li>limit vocabulary size (<code>max_features=5000</code>),</li>
<li>use English stop words (<code>stop_words='english'</code>).</li>
</ul>
</li>
<li>Fit an <code>LatentDirichletAllocation</code> model with:<ul>
<li><code>n_components=10</code> (topics),</li>
<li><code>learning_method='batch'</code> (use full dataset at once),</li>
<li><code>random_state=123</code> for reproducibility.</li>
</ul>
</li>
<li>Access <code>lda.components_</code>:<ul>
<li>shape <code>(n_topics, n_words)</code>,</li>
<li>each row contains word importance for a given topic.</li>
</ul>
</li>
<li>For each topic, sort the word importances and print the <strong>top N words</strong>.</li>
</ol>
<p>The result is a set of interpretable topics, for example:</p>
<ul>
<li>Topic 1: <em>worst minutes awful script stupid</em></li>
<li>Topic 2: <em>family mother father children girl</em></li>
<li>Topic 3: <em>american war dvd music tv</em></li>
<li></li>
</ul>
<p>These topics give us a <strong>high-level view</strong> of what themes appear in the movie
reviews without using any labels.</p>
<p>Note: LDA here is <strong>separate</strong> from the sentiment classifier. In the next
chapter the authors show how to embed the classifier into a web app; LDA is
a standalone unsupervised example.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=79809c238db2fcfc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_extraction.text</span><span class="w"> </span><span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>


<span class="c1"># 1. Load movie_data and build bag-of-words matrix</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"movie_data.csv"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf-8"</span><span class="p">)</span>

<span class="n">count</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span>
    <span class="n">max_df</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>           <span class="c1"># ignore very frequent words (&gt;10% docs)</span>
    <span class="n">max_features</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>    <span class="c1"># keep 5000 most frequent words</span>
    <span class="n">stop_words</span><span class="o">=</span><span class="s2">"english"</span>
<span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"review"</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=7be4c042c83f79e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># 2. Fit LDA model with 10 topics</span>

<span class="n">lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span>
    <span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>      <span class="c1"># number of topics</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
    <span class="n">learning_method</span><span class="o">=</span><span class="s2">"batch"</span>
<span class="p">)</span>

<span class="n">X_topics</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Shape of components_: (n_topics, n_features)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"lda.components_.shape:"</span><span class="p">,</span> <span class="n">lda</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>lda.components_.shape: (10, 5000)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=74b488e6b7b669f5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span><span class="c1"># 3. Print the top words per topic</span>

<span class="n">n_top_words</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">count</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>

<span class="k">for</span> <span class="n">topic_idx</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lda</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Topic </span><span class="si">{</span><span class="n">topic_idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">:"</span><span class="p">)</span>
    <span class="n">top_indices</span> <span class="o">=</span> <span class="n">topic</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:</span><span class="o">-</span><span class="n">n_top_words</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># indices of top words</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_indices</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">top_words</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Topic 1:
worst minutes awful script stupid
Topic 2:
family mother father children girl
Topic 3:
american war dvd music tv
Topic 4:
human audience cinema art sense
Topic 5:
police guy car dead murder
Topic 6:
horror house sex girl woman
Topic 7:
role performance comedy actor performances
Topic 8:
series episode war episodes tv
Topic 9:
book version original read novel
Topic 10:
action fight guy guys cool
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1b2a9f76ea706fe5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Comparing-the-Different-Setups">Comparing the Different Setups<a class="anchor-link" href="#Comparing-the-Different-Setups"></a></h2><h3 id="5-Fold-Stratified-Cross-Validation">5-Fold Stratified Cross-Validation<a class="anchor-link" href="#5-Fold-Stratified-Cross-Validation"></a></h3><p>We use <strong>k-fold cross-validation</strong> to estimate how well our model will generalize and to choose good hyperparameters. In <strong>5-fold stratified CV</strong>:</p>
<ul>
<li>The training set is split into 5 folds.</li>
<li>We train 5 models, each time holding out a different fold as validation.</li>
<li>Scores are averaged across folds.</li>
<li><em>Stratified</em> means each fold keeps a similar positive/negative class ratio.</li>
</ul>
<p>Choosing <strong>5 folds instead of 10</strong> is a runtime vs stability trade-off:</p>
<ul>
<li>10-fold CV has slightly lower variance in the accuracy estimate, but is ~2 slower.</li>
<li>5-fold CV is much faster and still reliable on a large dataset like 50k reviews.</li>
</ul>
<p>In this project we obtain <strong>Test Accuracy  0.899</strong> with 5-fold stratified CV and a
grid-searched logistic regression model (TFIDF features).</p>
<hr/>
<h3 id="Out-of-Core-Learning-with-HashingVectorizer-+-SGDClassifier">Out-of-Core Learning with HashingVectorizer + SGDClassifier<a class="anchor-link" href="#Out-of-Core-Learning-with-HashingVectorizer-+-SGDClassifier"></a></h3><p>Out-of-core learning trains on <strong>mini-batches</strong> that are streamed from disk,
instead of loading the full dataset into memory. Here we use:</p>
<ul>
<li><code>HashingVectorizer</code> for features (no stored vocabulary, uses the hashing trick),</li>
<li><code>SGDClassifier(loss='log_loss', penalty='l2')</code> with <code>partial_fit</code> updates.</li>
</ul>
<p>This setup is very <strong>memory-efficient</strong> and fast for big data, but we do not run a
full grid search and we accept some information loss from hashing. As a result,
the accuracy (~0.84) is lower than the fully tuned in-memory logistic regression
(~0.899), but the example demonstrates how to scale to larger datasets.</p>
<hr/>
<h3 id="LDA-vs-Logistic-Regression-vs-k-NN">LDA vs Logistic Regression vs k-NN<a class="anchor-link" href="#LDA-vs-Logistic-Regression-vs-k-NN"></a></h3><ul>
<li><p><strong>Logistic Regression</strong> (this chapters main classifier):
Supervised, discriminative model that maps feature vectors to a probability of
the positive class. Used for sentiment classification.</p>
</li>
<li><p><strong>LDA (Latent Dirichlet Allocation)</strong>:
Unsupervised probabilistic topic model. Takes a bag-of-words matrix and
decomposes it into:</p>
<ul>
<li>a documenttopic matrix and</li>
<li>a topicword matrix.
Useful for discovering themes such as family drama, horror, etc., not for
direct sentiment labels.</li>
</ul>
</li>
<li><p><strong>k-NN (k-Nearest Neighbors)</strong>:
Supervised, non-parametric classifier that predicts a label by taking the
<strong>majority vote</strong> (mode) of the k closest training samples. Mentioned here as
another family of classifiers, but not used in this chapter.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=5ac231a37a9b0faf">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Logistic-Regression-vs-LDA-vs-PCA-vs-Kernel-PCA">Logistic Regression vs LDA vs PCA vs Kernel PCA<a class="anchor-link" href="#Logistic-Regression-vs-LDA-vs-PCA-vs-Kernel-PCA"></a></h3><p>In this chapter we mainly use <strong>logistic regression</strong> for sentiment classification,
but there are several related techniques that are easy to confuse:</p>
<h4 id="Logistic-Regression">Logistic Regression<a class="anchor-link" href="#Logistic-Regression"></a></h4><ul>
<li>Supervised classifier.</li>
<li>Models (P(y=1 \mid x)) using the logistic (sigmoid) function.</li>
<li>Learns a linear decision boundary in feature space.</li>
<li>Used here with TFIDF features for IMDB review sentiment (positive vs negative).</li>
</ul>
<h4 id="Linear-Discriminant-Analysis-(LDA)">Linear Discriminant Analysis (LDA)<a class="anchor-link" href="#Linear-Discriminant-Analysis-(LDA)"></a></h4><ul>
<li><strong>This is a different LDA</strong> from the topic model Latent Dirichlet Allocation.</li>
<li>Supervised dimensionality reduction + classifier.</li>
<li>Finds directions that:<ul>
<li>maximize the distance between class means, and</li>
<li>minimize the variance within each class.</li>
</ul>
</li>
<li>Uses label information directly and is designed to separate classes well.</li>
<li>Can be used as:<ul>
<li>a classifier in its own right, or</li>
<li>a feature extractor before another classifier.</li>
</ul>
</li>
</ul>
<h4 id="PCA-(Principal-Component-Analysis)">PCA (Principal Component Analysis)<a class="anchor-link" href="#PCA-(Principal-Component-Analysis)"></a></h4><ul>
<li>Unsupervised dimensionality reduction.</li>
<li>Ignores class labels and focuses on directions of <strong>maximum variance</strong>.</li>
<li>Often used for:<ul>
<li>compressing high-dimensional features,</li>
<li>denoising,</li>
<li>visualization (e.g. projecting to 2D/3D).</li>
</ul>
</li>
</ul>
<h4 id="Kernel-PCA-(KPCA)">Kernel PCA (KPCA)<a class="anchor-link" href="#Kernel-PCA-(KPCA)"></a></h4><ul>
<li>Nonlinear extension of PCA.</li>
<li>Uses kernel functions (e.g. RBF kernel) to perform PCA in an implicit
high-dimensional feature space.</li>
<li>Captures <strong>nonlinear</strong> structure in the data, useful when linear PCA is not
expressive enough.</li>
</ul>
<p>In short:</p>
<ul>
<li><strong>Logistic Regression</strong>  supervised classifier for predicting labels.</li>
<li><strong>Linear Discriminant Analysis</strong>  supervised dimensionality reduction that
explicitly tries to separate classes.</li>
<li><strong>PCA / Kernel PCA</strong>  unsupervised dimensionality reduction methods that find
useful low-dimensional representations (linear for PCA, nonlinear for KPCA),
without using class labels.</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3838377fab31cae1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython2"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
